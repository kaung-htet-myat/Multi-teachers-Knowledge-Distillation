{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Hydra_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPzVnTnhHEt7egfCFEueS3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaung-htet-myat/Multi-teachers-Knowledge-Distillation/blob/master/Hydra_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models to train:\n",
        "1. resnet20\n",
        "2. resnet14\n",
        "3. resnet32\n",
        "4. resnet44"
      ],
      "metadata": {
        "id": "LfF18-BEWAXh",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!nvidia-smi --query-gpu=gpu_name --format=csv,noheader"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "metadata": {
        "id": "VOBf9Dl2COkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d38c019d-b1a9-433b-80f4-9d1ce8ed9dc5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# save test\r\n",
        "import sys\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "import scipy as sp\r\n",
        "from scipy.stats import entropy\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "\r\n",
        "from nets.keras_resnet import resnet_v1, resnet_v2\r\n",
        "from nets.student_model_multeacherKD import resnet_student\r\n",
        "from nets.student_model_multeacherKD_wo_GT import resnet_student_wo_GT"
      ],
      "outputs": [],
      "metadata": {
        "id": "GHtnE3lBScnG",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "seed = 6\r\n",
        "batch_size = 32\r\n",
        "temperature = 4\r\n",
        "alpha = 0.5"
      ],
      "outputs": [],
      "metadata": {
        "id": "vg5ut4pXwyqS",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# js_divergence\r\n",
        "\r\n",
        "def JS_Divergence(softmaxes):\r\n",
        "  softsum = np.zeros(softmaxes[0].shape)\r\n",
        "  jsd = 0.0\r\n",
        "\r\n",
        "  for i in softmaxes:\r\n",
        "    j = np.asarray(i) \r\n",
        "    j = j/j.sum()\r\n",
        "    softsum += j\r\n",
        "\r\n",
        "  m = 1./3*softsum \r\n",
        "\r\n",
        "  for i in softmaxes:\r\n",
        "    j = np.asarray(i)\r\n",
        "    jsd += sp.stats.entropy(j,m, base=np.e)/5.\r\n",
        "\r\n",
        "  return jsd"
      ],
      "outputs": [],
      "metadata": {
        "id": "GWrDB_QN15iK",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def kd_loss(y_true, y_pred):\r\n",
        "\r\n",
        "  '''\r\n",
        "    Calculate modified Kullback-Leibler Divergence between ground truths and prediction.\r\n",
        "  '''\r\n",
        "\r\n",
        "  y_true_normal = y_true[:,:10]\r\n",
        "  y_true_soft = y_true[:,10:]\r\n",
        "  y_pred_normal = y_pred[:,:10]\r\n",
        "  y_pred_soft = y_pred[:, 10:]\r\n",
        "\r\n",
        "  t = temperature\r\n",
        "\r\n",
        "  #a = tf.keras.losses.kullback_leibler_divergence(y_true_soft, y_pred_soft) # kl divergence between softened logits of teacher and student\r\n",
        "  a = tf.keras.losses.categorical_crossentropy(y_true_soft, y_pred_soft)\r\n",
        "  b = tf.keras.losses.categorical_crossentropy(y_true_normal, y_pred_normal) # cross entropy between student's prediction and ground truth label\r\n",
        "\r\n",
        "  return a*(alpha*t*t)+b*(1-alpha)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "fEk4Pb7tltT_",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def js_loss(y_true, y_pred):\r\n",
        "\r\n",
        "  '''\r\n",
        "    Calculate jensen_shennon_divergence between ground truths and prediction.\r\n",
        "  '''\r\n",
        "\r\n",
        "  return nsl.lib.jensen_shannon_divergence(np.array(y_true), tf.keras.utils.to_categorical(np.argmax(np.array(y_pred), axis=1)), axis=1) # js divergence between logits of teacher and student"
      ],
      "outputs": [],
      "metadata": {
        "id": "oERzXqRKEHcy",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def kd_evaluate(y_true, y_pred):\n",
        "    y_pred_normal = y_pred[:,:10]\n",
        "    \n",
        "    #return tf.keras.metrics.categorical_accuracy(y_true, y_pred_normal)\n",
        "    \n",
        "    m = tf.keras.metrics.CategoricalAccuracy()\n",
        "    #_ = m.update_state(y_true, y_pred_normal) \n",
        "\n",
        "    m(y_true, y_pred_normal)\n",
        "  \n",
        "    acc = m.result().numpy() \n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    loss = cce(y_true, y_pred_normal).numpy()\n",
        "    \n",
        "    return (loss,acc)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Dv7h7aMkOb7r",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def multihead_kd_evaluate(y_true, y_pred):\n",
        "\n",
        "    #y_pred_normal = y_pred[:,:,:10] # (4,1000,10)\n",
        "    \n",
        "    #return tf.keras.metrics.categorical_accuracy(y_true, y_pred_normal)\n",
        "\n",
        "    pred = []\n",
        "    acc = []\n",
        "    loss = []\n",
        "    \n",
        "    m = tf.keras.metrics.CategoricalAccuracy()\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    #_ = m.update_state(y_true, y_pred_normal) \n",
        "\n",
        "    for i in range(len(y_pred)): # 4\n",
        "      m(y_true, y_pred[i][:,:10])\n",
        "      pred.append(y_pred[i][:,:10])\n",
        "      acc.append(m.result().numpy()) \n",
        "      loss.append(cce(y_true, y_pred[i][:,:10]).numpy())\n",
        "      m.reset_states\n",
        "\n",
        "    pred = np.array(pred)\n",
        "    avg_pred = pred.mean(axis=0)\n",
        "    m(y_true, avg_pred)\n",
        "    avg_acc = m.result().numpy()\n",
        "    m.reset_states\n",
        "    \n",
        "    return (loss,acc, avg_acc)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Vb1xe-taluIq",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def new_softmax(logits, temperature=1):\n",
        "\n",
        "  '''\n",
        "    Annealing the temperature of the softmax.\n",
        "  '''\n",
        "  logits = logits/temperature\n",
        "  return np.exp(logits)/np.sum(np.exp(logits))"
      ],
      "outputs": [],
      "metadata": {
        "id": "weoLNsmClwxZ",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "94RwbDyc3ffY",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "train_data, test_data = train_data.astype('float32')/255. , test_data.astype('float32')/255.\n",
        "train_labels, test_labels = train_labels.astype('int32'), test_labels.astype('int32')\n",
        "\n",
        "x_train_mean = np.mean(train_data, axis=0)\n",
        "train_data -= x_train_mean\n",
        "test_data -= x_train_mean\n",
        "\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
        "\n",
        "def random_shift(image):\n",
        "    return  tf.keras.preprocessing.image.random_shift(image, 0.1, 0.1,  row_axis=0, col_axis=1, channel_axis=2)\n",
        "\n",
        "def augment(image, label):\n",
        "    image = tf.numpy_function(random_shift, [image], tf.float32)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    return image, label\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
        "train_ds = train_ds.shuffle(10000, seed=seed)\n",
        "train_ds = train_ds.map(augment)\n",
        "train_ds = train_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "train_steps_per_epoch = tf.data.experimental.cardinality(train_ds)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
        "test_ds = test_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ],
      "metadata": {
        "id": "Ft_d5mkfUcpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a66f9f59-6051-472c-f384-44cd1853a094"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teacher Models Loading"
      ],
      "metadata": {
        "id": "vwuMP_EPKceG",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "resnet_20 = tf.keras.models.load_model('models/resnet_20')\n",
        "resnet_20.evaluate(test_data, test_labels)\n",
        "\n",
        "pred = resnet_20(test_data)\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "m(test_labels, pred)\n",
        "print(\"Accuracy: \",m.result().numpy())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5051 - accuracy: 0.8766\n",
            "Accuracy:  0.8766\n"
          ]
        }
      ],
      "metadata": {
        "id": "wmw_mKVGKfak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1494d403-8850-4fbb-8497-c740a6ab62ee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "resnet_14 = tf.keras.models.load_model('models/resnet_14')\n",
        "resnet_14.evaluate(test_data, test_labels)\n",
        "\n",
        "pred = resnet_14(test_data)\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "m(test_labels, pred)\n",
        "print(\"Accuracy: \",m.result().numpy())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8612\n"
          ]
        }
      ],
      "metadata": {
        "id": "oAq0NKb6K1bu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20b292ec-fe52-4c8e-9464-84fb3e99bdf0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "resnet_32 = tf.keras.models.load_model('models/resnet_32')\n",
        "resnet_32.evaluate(test_data, test_labels)\n",
        "\n",
        "pred = resnet_32(test_data)\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "m(test_labels, pred)\n",
        "print(\"Accuracy: \",m.result().numpy())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5683 - accuracy: 0.8672\n",
            "Accuracy:  0.8672\n"
          ]
        }
      ],
      "metadata": {
        "id": "Z1VrUOpMK1ee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "51dab7a5-822d-4496-b383-69323811e274"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "resnet_44 = tf.keras.models.load_model('models/resnet_44')\n",
        "resnet_44.evaluate(test_data, test_labels)\n",
        "\n",
        "pred = resnet_44(test_data)\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "m(test_labels, pred)\n",
        "print(\"Accuracy: \",m.result().numpy())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 0.5796 - accuracy: 0.8735\n",
            "Accuracy:  0.8735\n"
          ]
        }
      ],
      "metadata": {
        "id": "FArETnucK1iI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7d56ab9-dd41-4927-aade-a59d9fb3bde6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teachers' logits extractions"
      ],
      "metadata": {
        "id": "wYxebEcyl-C5",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def new_labels(model, data, label, t, g_truth=False):\n",
        "  model_sans_softmax = keras.models.Model(inputs=model.input, outputs = model.get_layer('logits').output)\n",
        "  new_logits = model_sans_softmax.predict(data)\n",
        "  unsoftened_prob = new_softmax(new_logits, 1)\n",
        "  softened_prob = new_softmax(new_logits, t)\n",
        "  if g_truth:\n",
        "    labels = np.hstack([label, softened_prob])\n",
        "  else:\n",
        "    labels = softened_prob\n",
        "\n",
        "  return labels"
      ],
      "outputs": [],
      "metadata": {
        "id": "FFsQY9ggsCfL",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ,g_truth=True\n",
        "rn20_train_labels = new_labels(resnet_20, train_data, train_labels, t=temperature)\n",
        "rn20_test_labels = new_labels(resnet_20, test_data, test_labels, t=temperature)\n",
        "print(rn20_train_labels.shape)\n",
        "print(rn20_test_labels.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ],
      "metadata": {
        "id": "7yH9S6zWeihr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "513ac356-e3a7-4163-e9e1-9b2fecc510b4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rn14_train_labels = new_labels(resnet_14, train_data, train_labels, t=temperature)\n",
        "rn14_test_labels = new_labels(resnet_14, test_data, test_labels, t=temperature)\n",
        "print(rn14_train_labels.shape)\n",
        "print(rn14_test_labels.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ],
      "metadata": {
        "id": "ln7NRDkrfp6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "18c4ea1e-451e-420c-84cb-8e1dadc01615"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rn32_train_labels = new_labels(resnet_32, train_data, train_labels, t=temperature)\n",
        "rn32_test_labels = new_labels(resnet_32, test_data, test_labels, t=temperature)\n",
        "print(rn32_train_labels.shape)\n",
        "print(rn32_test_labels.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ],
      "metadata": {
        "id": "uNJnorjBfqN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "53bea16d-6ad9-4d4d-f086-5cdf861ef760"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rn44_train_labels = new_labels(resnet_44, train_data, train_labels, t=temperature)\n",
        "rn44_test_labels = new_labels(resnet_44, test_data, test_labels, t=temperature)\n",
        "print(rn44_train_labels.shape)\n",
        "print(rn44_test_labels.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ]
        }
      ],
      "metadata": {
        "id": "GAUb7TP1einW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fb0c009-5a16-4d59-9a8c-c4186c840cf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Student Data Augmentation (with tf.data)"
      ],
      "metadata": {
        "id": "BOikN8pD9XzH",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "student_train_ds = tf.data.Dataset.from_tensor_slices((train_data, {'soft_prob_1':rn14_train_labels,'soft_prob_2':rn20_train_labels,'soft_prob_3':rn32_train_labels,'soft_prob_4':rn44_train_labels}))\n",
        "student_train_ds = student_train_ds.shuffle(10000, seed=seed)\n",
        "student_train_ds = student_train_ds.map(augment)\n",
        "student_train_ds = student_train_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "train_steps_per_epoch = tf.data.experimental.cardinality(student_train_ds)\n",
        "\n",
        "student_test_ds = tf.data.Dataset.from_tensor_slices((test_data, {'soft_prob_1':test_labels,'soft_prob_2':test_labels,'soft_prob_3':test_labels,'soft_prob_4':test_labels}))\n",
        "student_test_ds = student_test_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "outputs": [],
      "metadata": {
        "id": "hhhnanMK9dIE",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# hinton datsets\n",
        "\n",
        "hinton_train_labels = [rn14_train_labels, rn20_train_labels, rn32_train_labels, rn44_train_labels]\n",
        "hinton_train_labels = np.array(hinton_train_labels)\n",
        "hinton_train_labels = hinton_train_labels.mean(axis=0)\n",
        "print(hinton_train_labels.shape)\n",
        "\n",
        "hinton_train_ds = tf.data.Dataset.from_tensor_slices((train_data, hinton_train_labels))\n",
        "hinton_train_ds = hinton_train_ds.shuffle(10000, seed=seed)\n",
        "hinton_train_ds = hinton_train_ds.map(augment)\n",
        "hinton_train_ds = hinton_train_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "hinton_test_labels = [rn14_test_labels, rn20_test_labels, rn32_test_labels, rn44_test_labels]\n",
        "hinton_test_labels = np.array(hinton_test_labels)\n",
        "hinton_test_labels = hinton_test_labels.mean(axis=0)\n",
        "\n",
        "hinton_test_ds = tf.data.Dataset.from_tensor_slices((test_data, hinton_test_labels))\n",
        "hinton_test_ds = hinton_test_ds.shuffle(10000, seed=seed)\n",
        "hinton_test_ds = hinton_test_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "p7E7amg6pE8a",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Hydra and Hinton Models"
      ],
      "metadata": {
        "id": "bbzHUBThhzX7",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "depth = 20"
      ],
      "outputs": [],
      "metadata": {
        "id": "LY-nboLrsQyT",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "hydra = resnet_student_wo_GT((32,32,3), temperature=temperature, body_depth=depth, num_blocks_head=1, num_classes=10)\n",
        "hydra.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 16)   2320        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 16)   0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 32, 32, 16)   0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 16)   2320        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 16)   2320        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 32, 32, 16)   0           activation_18[0][0]              \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 32)   4640        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 32)   9248        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 32)   544         activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 32)   0           conv2d_24[0][0]                  \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 32)   9248        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 32)   9248        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 16, 16, 32)   0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 32)   9248        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 32)   9248        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 16, 16, 32)   0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 64)     18496       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 64)     36928       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 64)     2112        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 64)     0           conv2d_31[0][0]                  \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 64)     36928       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 64)     36928       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 64)     0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 64)     256         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 64)     256         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 64)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 64)     0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 64)     36928       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 64)     36928       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 64)     36928       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 64)     36928       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 64)     256         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 64)     0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 64)     0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 64)     0           activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 64)     0           activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 1, 1, 64)     0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 64)           0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 64)           0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "logits_1 (Dense)                (None, 10)           650         flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_2 (Dense)                (None, 10)           650         flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_3 (Dense)                (None, 10)           650         flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_4 (Dense)                (None, 10)           650         flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 10)           0           logits_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 10)           0           logits_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 10)           0           logits_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 10)           0           logits_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_1 (Activation)        (None, 10)           0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_2 (Activation)        (None, 10)           0           lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_3 (Activation)        (None, 10)           0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_4 (Activation)        (None, 10)           0           lambda_3[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 499,496\n",
            "Trainable params: 497,352\n",
            "Non-trainable params: 2,144\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "id": "Bx9ZMVtnmc9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afaa5318-6ad6-47ef-8c68-1e773058f5a6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "hinton_head = resnet_student((32,32,3), temperature=temperature, body_depth=depth, num_head=1, num_blocks_head=1, num_classes=10)\n",
        "hinton_head.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 32, 32, 16)   448         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 32, 32, 16)   64          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 32, 32, 16)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 16)   2320        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 32, 32, 16)   64          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 32, 32, 16)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 32, 32, 16)   2320        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 32, 32, 16)   64          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 32, 32, 16)   0           activation_39[0][0]              \n",
            "                                                                 batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 32, 32, 16)   0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 32, 32, 16)   2320        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 32, 32, 16)   64          conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 32, 32, 16)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 32, 32, 16)   2320        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 32, 32, 16)   64          conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 32, 32, 16)   0           activation_41[0][0]              \n",
            "                                                                 batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 32, 32, 16)   0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 32, 32, 16)   2320        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 32, 32, 16)   64          conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 32, 32, 16)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 32, 32, 16)   2320        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 32, 32, 16)   64          conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 32, 32, 16)   0           activation_43[0][0]              \n",
            "                                                                 batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 32, 32, 16)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 32)   4640        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 32)   128         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 32)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 32)   9248        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 32)   544         activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 32)   128         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 16, 16, 32)   0           conv2d_51[0][0]                  \n",
            "                                                                 batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 32)   0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 32)   9248        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 32)   128         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 32)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 32)   9248        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 32)   128         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 16, 16, 32)   0           activation_47[0][0]              \n",
            "                                                                 batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 32)   0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 32)   9248        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 32)   128         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 32)   128         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 16, 16, 32)   0           activation_49[0][0]              \n",
            "                                                                 batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 32)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 8, 8, 64)     18496       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 8, 8, 64)     36928       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 8, 8, 64)     2112        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 8, 8, 64)     0           conv2d_58[0][0]                  \n",
            "                                                                 batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 8, 8, 64)     0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 8, 8, 64)     36928       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 8, 8, 64)     36928       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              \n",
            "                                                                 batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 8, 8, 64)     36928       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 8, 8, 64)     36928       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 8, 8, 64)     256         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 8, 8, 64)     0           activation_55[0][0]              \n",
            "                                                                 batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 1, 1, 64)     0           activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 64)           0           average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "logits_1 (Dense)                (None, 10)           650         flatten_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 10)           0           logits_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "softmax_1 (Activation)          (None, 10)           0           logits_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_1 (Activation)        (None, 10)           0           lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20)           0           softmax_1[0][0]                  \n",
            "                                                                 soft_prob_1[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "id": "vvTCfiS5Us3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da1027e6-1743-4e23-e503-f0a56f2452fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hinton Head Training"
      ],
      "metadata": {
        "id": "JTYKvSDzYkPg",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "filepath = ('models/hinton_cp/cp.ckpt')\n",
        "\n",
        "hinton_cp = keras.callbacks.ModelCheckpoint(filepath, verbose=1, save_weights_only=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "E1lslsYQh7s2",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "class TimingCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, logs={}):\n",
        "        self.logs=[]\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.starttime = timer()\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(timer()-self.starttime)\n",
        "\n",
        "time_hinton = TimingCallback()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Pp2Pr9zew95e",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def lr_schedule(epoch):\n",
        "  lr = 1e-3\n",
        "  if epoch>=25:\n",
        "    lr*= 1e-1\n",
        "  elif epoch>=50:\n",
        "    lr*= 1e-2\n",
        "  elif epoch>=100:\n",
        "    lr*= 1e-3\n",
        "  return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
      ],
      "outputs": [],
      "metadata": {
        "id": "2o5XL3bDcT1K",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sgd = tf.keras.optimizers.SGD(learning_rate=lr_schedule(0), momentum=0.9)"
      ],
      "outputs": [],
      "metadata": {
        "id": "_DoZk4yfcIoX",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "hinton_head.compile(optimizer=sgd, loss=kd_loss, metrics=['accuracy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Arb81MZQiF6L",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "hinton_hist = hinton_head.fit(hinton_train_ds, epochs=150, validation_data=(hinton_test_ds), callbacks=[hinton_cp, time_hinton, lr_scheduler])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.6661 - accuracy: 0.2646\n",
            "Epoch 00001: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6661 - accuracy: 0.2646 - val_loss: 0.6449 - val_accuracy: 0.3352 - lr: 0.0010\n",
            "Epoch 2/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5967 - accuracy: 0.3633\n",
            "Epoch 00002: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5967 - accuracy: 0.3634 - val_loss: 0.6010 - val_accuracy: 0.4024 - lr: 0.0010\n",
            "Epoch 3/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.4088\n",
            "Epoch 00003: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5674 - accuracy: 0.4088 - val_loss: 0.5769 - val_accuracy: 0.4370 - lr: 0.0010\n",
            "Epoch 4/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5474 - accuracy: 0.4332\n",
            "Epoch 00004: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5474 - accuracy: 0.4333 - val_loss: 0.5585 - val_accuracy: 0.4583 - lr: 0.0010\n",
            "Epoch 5/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5330 - accuracy: 0.4578\n",
            "Epoch 00005: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5330 - accuracy: 0.4579 - val_loss: 0.5495 - val_accuracy: 0.4716 - lr: 0.0010\n",
            "Epoch 6/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5213 - accuracy: 0.4735\n",
            "Epoch 00006: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5213 - accuracy: 0.4735 - val_loss: 0.5351 - val_accuracy: 0.4911 - lr: 0.0010\n",
            "Epoch 7/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5122 - accuracy: 0.4850\n",
            "Epoch 00007: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5122 - accuracy: 0.4851 - val_loss: 0.5273 - val_accuracy: 0.5041 - lr: 0.0010\n",
            "Epoch 8/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.4991\n",
            "Epoch 00008: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5022 - accuracy: 0.4992 - val_loss: 0.5328 - val_accuracy: 0.5017 - lr: 0.0010\n",
            "Epoch 9/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.5143\n",
            "Epoch 00009: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4923 - accuracy: 0.5143 - val_loss: 0.5128 - val_accuracy: 0.5281 - lr: 0.0010\n",
            "Epoch 10/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4838 - accuracy: 0.5259\n",
            "Epoch 00010: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4838 - accuracy: 0.5258 - val_loss: 0.5122 - val_accuracy: 0.5335 - lr: 0.0010\n",
            "Epoch 11/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.4750 - accuracy: 0.5413\n",
            "Epoch 00011: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4750 - accuracy: 0.5413 - val_loss: 0.4894 - val_accuracy: 0.5629 - lr: 0.0010\n",
            "Epoch 12/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.5490\n",
            "Epoch 00012: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4659 - accuracy: 0.5489 - val_loss: 0.4858 - val_accuracy: 0.5721 - lr: 0.0010\n",
            "Epoch 13/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.5630\n",
            "Epoch 00013: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4589 - accuracy: 0.5630 - val_loss: 0.4845 - val_accuracy: 0.5675 - lr: 0.0010\n",
            "Epoch 14/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.5737\n",
            "Epoch 00014: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4516 - accuracy: 0.5737 - val_loss: 0.4715 - val_accuracy: 0.5868 - lr: 0.0010\n",
            "Epoch 15/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.4454 - accuracy: 0.5812\n",
            "Epoch 00015: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4454 - accuracy: 0.5812 - val_loss: 0.4922 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 16/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4376 - accuracy: 0.5887\n",
            "Epoch 00016: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4377 - accuracy: 0.5887 - val_loss: 0.4668 - val_accuracy: 0.5919 - lr: 0.0010\n",
            "Epoch 17/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4317 - accuracy: 0.5981\n",
            "Epoch 00017: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4317 - accuracy: 0.5981 - val_loss: 0.4488 - val_accuracy: 0.6150 - lr: 0.0010\n",
            "Epoch 18/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.4251 - accuracy: 0.6053\n",
            "Epoch 00018: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4252 - accuracy: 0.6052 - val_loss: 0.4475 - val_accuracy: 0.6177 - lr: 0.0010\n",
            "Epoch 19/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.6136\n",
            "Epoch 00019: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4192 - accuracy: 0.6136 - val_loss: 0.4397 - val_accuracy: 0.6254 - lr: 0.0010\n",
            "Epoch 20/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4149 - accuracy: 0.6198\n",
            "Epoch 00020: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4150 - accuracy: 0.6197 - val_loss: 0.4417 - val_accuracy: 0.6224 - lr: 0.0010\n",
            "Epoch 21/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4094 - accuracy: 0.6273\n",
            "Epoch 00021: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4094 - accuracy: 0.6272 - val_loss: 0.4454 - val_accuracy: 0.6228 - lr: 0.0010\n",
            "Epoch 22/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.6328\n",
            "Epoch 00022: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4038 - accuracy: 0.6328 - val_loss: 0.4327 - val_accuracy: 0.6321 - lr: 0.0010\n",
            "Epoch 23/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.6386\n",
            "Epoch 00023: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3998 - accuracy: 0.6386 - val_loss: 0.4375 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 24/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3951 - accuracy: 0.6406\n",
            "Epoch 00024: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3951 - accuracy: 0.6406 - val_loss: 0.4309 - val_accuracy: 0.6409 - lr: 0.0010\n",
            "Epoch 25/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3920 - accuracy: 0.6481\n",
            "Epoch 00025: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3920 - accuracy: 0.6481 - val_loss: 0.4274 - val_accuracy: 0.6383 - lr: 0.0010\n",
            "Epoch 26/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.6598\n",
            "Epoch 00026: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3831 - accuracy: 0.6598 - val_loss: 0.4129 - val_accuracy: 0.6609 - lr: 1.0000e-04\n",
            "Epoch 27/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.6620\n",
            "Epoch 00027: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3816 - accuracy: 0.6618 - val_loss: 0.4101 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 28/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.6640\n",
            "Epoch 00028: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3805 - accuracy: 0.6640 - val_loss: 0.4108 - val_accuracy: 0.6632 - lr: 1.0000e-04\n",
            "Epoch 29/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.6621\n",
            "Epoch 00029: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3808 - accuracy: 0.6620 - val_loss: 0.4105 - val_accuracy: 0.6633 - lr: 1.0000e-04\n",
            "Epoch 30/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.6625\n",
            "Epoch 00030: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3810 - accuracy: 0.6625 - val_loss: 0.4108 - val_accuracy: 0.6656 - lr: 1.0000e-04\n",
            "Epoch 31/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.6636\n",
            "Epoch 00031: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3803 - accuracy: 0.6637 - val_loss: 0.4103 - val_accuracy: 0.6658 - lr: 1.0000e-04\n",
            "Epoch 32/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.6655\n",
            "Epoch 00032: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3795 - accuracy: 0.6655 - val_loss: 0.4098 - val_accuracy: 0.6638 - lr: 1.0000e-04\n",
            "Epoch 33/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.6658\n",
            "Epoch 00033: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3788 - accuracy: 0.6658 - val_loss: 0.4072 - val_accuracy: 0.6690 - lr: 1.0000e-04\n",
            "Epoch 34/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.6674\n",
            "Epoch 00034: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3782 - accuracy: 0.6674 - val_loss: 0.4074 - val_accuracy: 0.6675 - lr: 1.0000e-04\n",
            "Epoch 35/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3773 - accuracy: 0.6677\n",
            "Epoch 00035: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3773 - accuracy: 0.6677 - val_loss: 0.4068 - val_accuracy: 0.6694 - lr: 1.0000e-04\n",
            "Epoch 36/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.6656\n",
            "Epoch 00036: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3782 - accuracy: 0.6656 - val_loss: 0.4064 - val_accuracy: 0.6707 - lr: 1.0000e-04\n",
            "Epoch 37/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3765 - accuracy: 0.6680\n",
            "Epoch 00037: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3765 - accuracy: 0.6681 - val_loss: 0.4066 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
            "Epoch 38/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3769 - accuracy: 0.6668\n",
            "Epoch 00038: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3769 - accuracy: 0.6668 - val_loss: 0.4082 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 39/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.6681\n",
            "Epoch 00039: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3763 - accuracy: 0.6681 - val_loss: 0.4075 - val_accuracy: 0.6699 - lr: 1.0000e-04\n",
            "Epoch 40/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3752 - accuracy: 0.6679\n",
            "Epoch 00040: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3752 - accuracy: 0.6679 - val_loss: 0.4047 - val_accuracy: 0.6716 - lr: 1.0000e-04\n",
            "Epoch 41/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3755 - accuracy: 0.6681\n",
            "Epoch 00041: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3756 - accuracy: 0.6680 - val_loss: 0.4045 - val_accuracy: 0.6733 - lr: 1.0000e-04\n",
            "Epoch 42/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3751 - accuracy: 0.6685\n",
            "Epoch 00042: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3751 - accuracy: 0.6685 - val_loss: 0.4049 - val_accuracy: 0.6713 - lr: 1.0000e-04\n",
            "Epoch 43/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.6711\n",
            "Epoch 00043: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3738 - accuracy: 0.6711 - val_loss: 0.4042 - val_accuracy: 0.6727 - lr: 1.0000e-04\n",
            "Epoch 44/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3742 - accuracy: 0.6697\n",
            "Epoch 00044: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3742 - accuracy: 0.6696 - val_loss: 0.4024 - val_accuracy: 0.6752 - lr: 1.0000e-04\n",
            "Epoch 45/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.6695\n",
            "Epoch 00045: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3736 - accuracy: 0.6695 - val_loss: 0.4051 - val_accuracy: 0.6715 - lr: 1.0000e-04\n",
            "Epoch 46/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3728 - accuracy: 0.6726\n",
            "Epoch 00046: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3728 - accuracy: 0.6726 - val_loss: 0.4020 - val_accuracy: 0.6761 - lr: 1.0000e-04\n",
            "Epoch 47/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.6699\n",
            "Epoch 00047: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3732 - accuracy: 0.6699 - val_loss: 0.4019 - val_accuracy: 0.6751 - lr: 1.0000e-04\n",
            "Epoch 48/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3721 - accuracy: 0.6735\n",
            "Epoch 00048: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3721 - accuracy: 0.6736 - val_loss: 0.4019 - val_accuracy: 0.6760 - lr: 1.0000e-04\n",
            "Epoch 49/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3724 - accuracy: 0.6695\n",
            "Epoch 00049: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3724 - accuracy: 0.6696 - val_loss: 0.4039 - val_accuracy: 0.6736 - lr: 1.0000e-04\n",
            "Epoch 50/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3714 - accuracy: 0.6733\n",
            "Epoch 00050: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3714 - accuracy: 0.6733 - val_loss: 0.3995 - val_accuracy: 0.6771 - lr: 1.0000e-04\n",
            "Epoch 51/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.6740\n",
            "Epoch 00051: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3709 - accuracy: 0.6740 - val_loss: 0.4032 - val_accuracy: 0.6754 - lr: 1.0000e-04\n",
            "Epoch 52/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3703 - accuracy: 0.6759\n",
            "Epoch 00052: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3703 - accuracy: 0.6759 - val_loss: 0.3992 - val_accuracy: 0.6782 - lr: 1.0000e-04\n",
            "Epoch 53/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3696 - accuracy: 0.6733\n",
            "Epoch 00053: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3696 - accuracy: 0.6734 - val_loss: 0.3984 - val_accuracy: 0.6794 - lr: 1.0000e-04\n",
            "Epoch 54/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3696 - accuracy: 0.6754\n",
            "Epoch 00054: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3696 - accuracy: 0.6755 - val_loss: 0.3985 - val_accuracy: 0.6795 - lr: 1.0000e-04\n",
            "Epoch 55/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3686 - accuracy: 0.6766\n",
            "Epoch 00055: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3686 - accuracy: 0.6766 - val_loss: 0.3995 - val_accuracy: 0.6783 - lr: 1.0000e-04\n",
            "Epoch 56/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3683 - accuracy: 0.6771\n",
            "Epoch 00056: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3683 - accuracy: 0.6771 - val_loss: 0.3994 - val_accuracy: 0.6771 - lr: 1.0000e-04\n",
            "Epoch 57/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3681 - accuracy: 0.6758\n",
            "Epoch 00057: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3682 - accuracy: 0.6758 - val_loss: 0.3981 - val_accuracy: 0.6813 - lr: 1.0000e-04\n",
            "Epoch 58/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.6780\n",
            "Epoch 00058: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3685 - accuracy: 0.6780 - val_loss: 0.3963 - val_accuracy: 0.6831 - lr: 1.0000e-04\n",
            "Epoch 59/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3682 - accuracy: 0.6769\n",
            "Epoch 00059: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3682 - accuracy: 0.6769 - val_loss: 0.3993 - val_accuracy: 0.6792 - lr: 1.0000e-04\n",
            "Epoch 60/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.6790\n",
            "Epoch 00060: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3671 - accuracy: 0.6790 - val_loss: 0.3976 - val_accuracy: 0.6829 - lr: 1.0000e-04\n",
            "Epoch 61/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.6789\n",
            "Epoch 00061: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3662 - accuracy: 0.6789 - val_loss: 0.3974 - val_accuracy: 0.6817 - lr: 1.0000e-04\n",
            "Epoch 62/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3667 - accuracy: 0.6803\n",
            "Epoch 00062: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3666 - accuracy: 0.6803 - val_loss: 0.3999 - val_accuracy: 0.6777 - lr: 1.0000e-04\n",
            "Epoch 63/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.6835\n",
            "Epoch 00063: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3653 - accuracy: 0.6835 - val_loss: 0.3960 - val_accuracy: 0.6837 - lr: 1.0000e-04\n",
            "Epoch 64/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3656 - accuracy: 0.6811\n",
            "Epoch 00064: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3656 - accuracy: 0.6811 - val_loss: 0.3992 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
            "Epoch 65/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3649 - accuracy: 0.6810\n",
            "Epoch 00065: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3649 - accuracy: 0.6811 - val_loss: 0.3956 - val_accuracy: 0.6831 - lr: 1.0000e-04\n",
            "Epoch 66/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.6805\n",
            "Epoch 00066: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3653 - accuracy: 0.6806 - val_loss: 0.3959 - val_accuracy: 0.6841 - lr: 1.0000e-04\n",
            "Epoch 67/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.6805\n",
            "Epoch 00067: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3653 - accuracy: 0.6805 - val_loss: 0.3949 - val_accuracy: 0.6854 - lr: 1.0000e-04\n",
            "Epoch 68/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3639 - accuracy: 0.6824\n",
            "Epoch 00068: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3639 - accuracy: 0.6824 - val_loss: 0.3944 - val_accuracy: 0.6831 - lr: 1.0000e-04\n",
            "Epoch 69/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3641 - accuracy: 0.6804\n",
            "Epoch 00069: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 27ms/step - loss: 0.3641 - accuracy: 0.6804 - val_loss: 0.3940 - val_accuracy: 0.6876 - lr: 1.0000e-04\n",
            "Epoch 70/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3631 - accuracy: 0.6820\n",
            "Epoch 00070: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3632 - accuracy: 0.6820 - val_loss: 0.3959 - val_accuracy: 0.6860 - lr: 1.0000e-04\n",
            "Epoch 71/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3634 - accuracy: 0.6821\n",
            "Epoch 00071: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3634 - accuracy: 0.6821 - val_loss: 0.3931 - val_accuracy: 0.6858 - lr: 1.0000e-04\n",
            "Epoch 72/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3625 - accuracy: 0.6845\n",
            "Epoch 00072: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3625 - accuracy: 0.6845 - val_loss: 0.3936 - val_accuracy: 0.6888 - lr: 1.0000e-04\n",
            "Epoch 73/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.6842\n",
            "Epoch 00073: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3619 - accuracy: 0.6842 - val_loss: 0.3926 - val_accuracy: 0.6867 - lr: 1.0000e-04\n",
            "Epoch 74/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.6870\n",
            "Epoch 00074: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3610 - accuracy: 0.6870 - val_loss: 0.3932 - val_accuracy: 0.6862 - lr: 1.0000e-04\n",
            "Epoch 75/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3607 - accuracy: 0.6861\n",
            "Epoch 00075: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3606 - accuracy: 0.6862 - val_loss: 0.3905 - val_accuracy: 0.6909 - lr: 1.0000e-04\n",
            "Epoch 76/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3596 - accuracy: 0.6883\n",
            "Epoch 00076: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3596 - accuracy: 0.6884 - val_loss: 0.3917 - val_accuracy: 0.6874 - lr: 1.0000e-04\n",
            "Epoch 77/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3604 - accuracy: 0.6858\n",
            "Epoch 00077: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3604 - accuracy: 0.6858 - val_loss: 0.3915 - val_accuracy: 0.6909 - lr: 1.0000e-04\n",
            "Epoch 78/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3600 - accuracy: 0.6875\n",
            "Epoch 00078: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3600 - accuracy: 0.6875 - val_loss: 0.3920 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
            "Epoch 79/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3597 - accuracy: 0.6890\n",
            "Epoch 00079: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3597 - accuracy: 0.6889 - val_loss: 0.3933 - val_accuracy: 0.6865 - lr: 1.0000e-04\n",
            "Epoch 80/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3587 - accuracy: 0.6877\n",
            "Epoch 00080: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3587 - accuracy: 0.6876 - val_loss: 0.3897 - val_accuracy: 0.6906 - lr: 1.0000e-04\n",
            "Epoch 81/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3597 - accuracy: 0.6871\n",
            "Epoch 00081: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3596 - accuracy: 0.6872 - val_loss: 0.3912 - val_accuracy: 0.6873 - lr: 1.0000e-04\n",
            "Epoch 82/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3575 - accuracy: 0.6918\n",
            "Epoch 00082: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3576 - accuracy: 0.6918 - val_loss: 0.3894 - val_accuracy: 0.6888 - lr: 1.0000e-04\n",
            "Epoch 83/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3571 - accuracy: 0.6896\n",
            "Epoch 00083: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3571 - accuracy: 0.6896 - val_loss: 0.3881 - val_accuracy: 0.6933 - lr: 1.0000e-04\n",
            "Epoch 84/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.6891\n",
            "Epoch 00084: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3571 - accuracy: 0.6891 - val_loss: 0.3889 - val_accuracy: 0.6940 - lr: 1.0000e-04\n",
            "Epoch 85/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3565 - accuracy: 0.6913\n",
            "Epoch 00085: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3565 - accuracy: 0.6912 - val_loss: 0.3890 - val_accuracy: 0.6934 - lr: 1.0000e-04\n",
            "Epoch 86/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3556 - accuracy: 0.6913\n",
            "Epoch 00086: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3556 - accuracy: 0.6913 - val_loss: 0.3893 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
            "Epoch 87/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3571 - accuracy: 0.6893\n",
            "Epoch 00087: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3572 - accuracy: 0.6893 - val_loss: 0.3879 - val_accuracy: 0.6942 - lr: 1.0000e-04\n",
            "Epoch 88/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3561 - accuracy: 0.6917\n",
            "Epoch 00088: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3561 - accuracy: 0.6917 - val_loss: 0.3909 - val_accuracy: 0.6893 - lr: 1.0000e-04\n",
            "Epoch 89/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3550 - accuracy: 0.6917\n",
            "Epoch 00089: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3551 - accuracy: 0.6917 - val_loss: 0.3904 - val_accuracy: 0.6926 - lr: 1.0000e-04\n",
            "Epoch 90/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3556 - accuracy: 0.6909\n",
            "Epoch 00090: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3557 - accuracy: 0.6909 - val_loss: 0.3857 - val_accuracy: 0.6958 - lr: 1.0000e-04\n",
            "Epoch 91/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.6924\n",
            "Epoch 00091: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3550 - accuracy: 0.6924 - val_loss: 0.3868 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
            "Epoch 92/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.6909\n",
            "Epoch 00092: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3547 - accuracy: 0.6909 - val_loss: 0.3873 - val_accuracy: 0.6963 - lr: 1.0000e-04\n",
            "Epoch 93/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3543 - accuracy: 0.6927\n",
            "Epoch 00093: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3543 - accuracy: 0.6927 - val_loss: 0.3857 - val_accuracy: 0.6970 - lr: 1.0000e-04\n",
            "Epoch 94/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3537 - accuracy: 0.6943\n",
            "Epoch 00094: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3537 - accuracy: 0.6944 - val_loss: 0.3882 - val_accuracy: 0.6953 - lr: 1.0000e-04\n",
            "Epoch 95/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.6944\n",
            "Epoch 00095: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3529 - accuracy: 0.6944 - val_loss: 0.3876 - val_accuracy: 0.6937 - lr: 1.0000e-04\n",
            "Epoch 96/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3526 - accuracy: 0.6953\n",
            "Epoch 00096: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3526 - accuracy: 0.6954 - val_loss: 0.3862 - val_accuracy: 0.6957 - lr: 1.0000e-04\n",
            "Epoch 97/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.6949\n",
            "Epoch 00097: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3529 - accuracy: 0.6951 - val_loss: 0.3862 - val_accuracy: 0.6940 - lr: 1.0000e-04\n",
            "Epoch 98/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.6946\n",
            "Epoch 00098: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3526 - accuracy: 0.6946 - val_loss: 0.3838 - val_accuracy: 0.7004 - lr: 1.0000e-04\n",
            "Epoch 99/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3520 - accuracy: 0.6949\n",
            "Epoch 00099: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3520 - accuracy: 0.6948 - val_loss: 0.3844 - val_accuracy: 0.6956 - lr: 1.0000e-04\n",
            "Epoch 100/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3518 - accuracy: 0.6955\n",
            "Epoch 00100: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3518 - accuracy: 0.6955 - val_loss: 0.3831 - val_accuracy: 0.6986 - lr: 1.0000e-04\n",
            "Epoch 101/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.6963\n",
            "Epoch 00101: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3509 - accuracy: 0.6962 - val_loss: 0.3841 - val_accuracy: 0.6981 - lr: 1.0000e-04\n",
            "Epoch 102/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.6946\n",
            "Epoch 00102: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3513 - accuracy: 0.6947 - val_loss: 0.3840 - val_accuracy: 0.6980 - lr: 1.0000e-04\n",
            "Epoch 103/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3499 - accuracy: 0.6989\n",
            "Epoch 00103: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3498 - accuracy: 0.6989 - val_loss: 0.3798 - val_accuracy: 0.7025 - lr: 1.0000e-04\n",
            "Epoch 104/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.6987\n",
            "Epoch 00104: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3505 - accuracy: 0.6987 - val_loss: 0.3818 - val_accuracy: 0.7019 - lr: 1.0000e-04\n",
            "Epoch 105/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3495 - accuracy: 0.7003\n",
            "Epoch 00105: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3495 - accuracy: 0.7003 - val_loss: 0.3823 - val_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 106/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.7004\n",
            "Epoch 00106: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3480 - accuracy: 0.7004 - val_loss: 0.3818 - val_accuracy: 0.7017 - lr: 1.0000e-04\n",
            "Epoch 107/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3483 - accuracy: 0.6987\n",
            "Epoch 00107: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3483 - accuracy: 0.6987 - val_loss: 0.3826 - val_accuracy: 0.6999 - lr: 1.0000e-04\n",
            "Epoch 108/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3487 - accuracy: 0.7013\n",
            "Epoch 00108: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3487 - accuracy: 0.7013 - val_loss: 0.3790 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
            "Epoch 109/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3476 - accuracy: 0.7003\n",
            "Epoch 00109: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3477 - accuracy: 0.7002 - val_loss: 0.3791 - val_accuracy: 0.7045 - lr: 1.0000e-04\n",
            "Epoch 110/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3472 - accuracy: 0.7013\n",
            "Epoch 00110: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3471 - accuracy: 0.7014 - val_loss: 0.3794 - val_accuracy: 0.7033 - lr: 1.0000e-04\n",
            "Epoch 111/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.7016\n",
            "Epoch 00111: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3460 - accuracy: 0.7016 - val_loss: 0.3800 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
            "Epoch 112/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3465 - accuracy: 0.7016\n",
            "Epoch 00112: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3465 - accuracy: 0.7015 - val_loss: 0.3807 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
            "Epoch 113/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3460 - accuracy: 0.7037\n",
            "Epoch 00113: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3460 - accuracy: 0.7037 - val_loss: 0.3788 - val_accuracy: 0.7044 - lr: 1.0000e-04\n",
            "Epoch 114/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3449 - accuracy: 0.7044\n",
            "Epoch 00114: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3450 - accuracy: 0.7044 - val_loss: 0.3778 - val_accuracy: 0.7042 - lr: 1.0000e-04\n",
            "Epoch 115/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3454 - accuracy: 0.7025\n",
            "Epoch 00115: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3455 - accuracy: 0.7024 - val_loss: 0.3790 - val_accuracy: 0.7033 - lr: 1.0000e-04\n",
            "Epoch 116/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3461 - accuracy: 0.7001\n",
            "Epoch 00116: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3461 - accuracy: 0.7001 - val_loss: 0.3803 - val_accuracy: 0.7026 - lr: 1.0000e-04\n",
            "Epoch 117/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3454 - accuracy: 0.7021\n",
            "Epoch 00117: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3454 - accuracy: 0.7021 - val_loss: 0.3794 - val_accuracy: 0.7047 - lr: 1.0000e-04\n",
            "Epoch 118/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.7005\n",
            "Epoch 00118: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3455 - accuracy: 0.7005 - val_loss: 0.3769 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
            "Epoch 119/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.7065\n",
            "Epoch 00119: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3437 - accuracy: 0.7065 - val_loss: 0.3785 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 120/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3439 - accuracy: 0.7055\n",
            "Epoch 00120: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3439 - accuracy: 0.7055 - val_loss: 0.3784 - val_accuracy: 0.7049 - lr: 1.0000e-04\n",
            "Epoch 121/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.7068\n",
            "Epoch 00121: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3433 - accuracy: 0.7068 - val_loss: 0.3749 - val_accuracy: 0.7085 - lr: 1.0000e-04\n",
            "Epoch 122/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3427 - accuracy: 0.7062\n",
            "Epoch 00122: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3427 - accuracy: 0.7062 - val_loss: 0.3786 - val_accuracy: 0.7018 - lr: 1.0000e-04\n",
            "Epoch 123/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3421 - accuracy: 0.7088\n",
            "Epoch 00123: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3421 - accuracy: 0.7087 - val_loss: 0.3792 - val_accuracy: 0.7032 - lr: 1.0000e-04\n",
            "Epoch 124/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3427 - accuracy: 0.7087\n",
            "Epoch 00124: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3427 - accuracy: 0.7087 - val_loss: 0.3768 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 125/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3421 - accuracy: 0.7053\n",
            "Epoch 00125: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3421 - accuracy: 0.7054 - val_loss: 0.3747 - val_accuracy: 0.7079 - lr: 1.0000e-04\n",
            "Epoch 126/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.7072\n",
            "Epoch 00126: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3432 - accuracy: 0.7072 - val_loss: 0.3754 - val_accuracy: 0.7075 - lr: 1.0000e-04\n",
            "Epoch 127/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.7093\n",
            "Epoch 00127: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3424 - accuracy: 0.7093 - val_loss: 0.3732 - val_accuracy: 0.7080 - lr: 1.0000e-04\n",
            "Epoch 128/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.7100\n",
            "Epoch 00128: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3402 - accuracy: 0.7101 - val_loss: 0.3760 - val_accuracy: 0.7059 - lr: 1.0000e-04\n",
            "Epoch 129/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3403 - accuracy: 0.7084\n",
            "Epoch 00129: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3404 - accuracy: 0.7084 - val_loss: 0.3737 - val_accuracy: 0.7100 - lr: 1.0000e-04\n",
            "Epoch 130/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.7083\n",
            "Epoch 00130: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3407 - accuracy: 0.7084 - val_loss: 0.3742 - val_accuracy: 0.7082 - lr: 1.0000e-04\n",
            "Epoch 131/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3406 - accuracy: 0.7084\n",
            "Epoch 00131: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3406 - accuracy: 0.7084 - val_loss: 0.3766 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 132/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3393 - accuracy: 0.7082\n",
            "Epoch 00132: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3393 - accuracy: 0.7082 - val_loss: 0.3757 - val_accuracy: 0.7057 - lr: 1.0000e-04\n",
            "Epoch 133/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3390 - accuracy: 0.7111\n",
            "Epoch 00133: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3390 - accuracy: 0.7112 - val_loss: 0.3734 - val_accuracy: 0.7071 - lr: 1.0000e-04\n",
            "Epoch 134/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.7102\n",
            "Epoch 00134: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3389 - accuracy: 0.7102 - val_loss: 0.3711 - val_accuracy: 0.7093 - lr: 1.0000e-04\n",
            "Epoch 135/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3388 - accuracy: 0.7104\n",
            "Epoch 00135: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3388 - accuracy: 0.7104 - val_loss: 0.3720 - val_accuracy: 0.7085 - lr: 1.0000e-04\n",
            "Epoch 136/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3385 - accuracy: 0.7110\n",
            "Epoch 00136: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3385 - accuracy: 0.7110 - val_loss: 0.3731 - val_accuracy: 0.7079 - lr: 1.0000e-04\n",
            "Epoch 137/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3379 - accuracy: 0.7122\n",
            "Epoch 00137: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3379 - accuracy: 0.7122 - val_loss: 0.3757 - val_accuracy: 0.7074 - lr: 1.0000e-04\n",
            "Epoch 138/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3370 - accuracy: 0.7145\n",
            "Epoch 00138: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3370 - accuracy: 0.7145 - val_loss: 0.3725 - val_accuracy: 0.7123 - lr: 1.0000e-04\n",
            "Epoch 139/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3371 - accuracy: 0.7110\n",
            "Epoch 00139: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3371 - accuracy: 0.7110 - val_loss: 0.3712 - val_accuracy: 0.7108 - lr: 1.0000e-04\n",
            "Epoch 140/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3374 - accuracy: 0.7127\n",
            "Epoch 00140: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3374 - accuracy: 0.7127 - val_loss: 0.3702 - val_accuracy: 0.7107 - lr: 1.0000e-04\n",
            "Epoch 141/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3370 - accuracy: 0.7156\n",
            "Epoch 00141: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3370 - accuracy: 0.7155 - val_loss: 0.3690 - val_accuracy: 0.7147 - lr: 1.0000e-04\n",
            "Epoch 142/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3356 - accuracy: 0.7150\n",
            "Epoch 00142: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3356 - accuracy: 0.7151 - val_loss: 0.3696 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 143/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.7146\n",
            "Epoch 00143: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3364 - accuracy: 0.7146 - val_loss: 0.3688 - val_accuracy: 0.7159 - lr: 1.0000e-04\n",
            "Epoch 144/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3358 - accuracy: 0.7134\n",
            "Epoch 00144: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3358 - accuracy: 0.7134 - val_loss: 0.3694 - val_accuracy: 0.7154 - lr: 1.0000e-04\n",
            "Epoch 145/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.7150\n",
            "Epoch 00145: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3342 - accuracy: 0.7150 - val_loss: 0.3698 - val_accuracy: 0.7121 - lr: 1.0000e-04\n",
            "Epoch 146/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3345 - accuracy: 0.7155\n",
            "Epoch 00146: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3345 - accuracy: 0.7155 - val_loss: 0.3698 - val_accuracy: 0.7147 - lr: 1.0000e-04\n",
            "Epoch 147/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.7152\n",
            "Epoch 00147: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3344 - accuracy: 0.7152 - val_loss: 0.3685 - val_accuracy: 0.7135 - lr: 1.0000e-04\n",
            "Epoch 148/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3337 - accuracy: 0.7150\n",
            "Epoch 00148: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3337 - accuracy: 0.7150 - val_loss: 0.3704 - val_accuracy: 0.7124 - lr: 1.0000e-04\n",
            "Epoch 149/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3340 - accuracy: 0.7160\n",
            "Epoch 00149: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3340 - accuracy: 0.7160 - val_loss: 0.3690 - val_accuracy: 0.7134 - lr: 1.0000e-04\n",
            "Epoch 150/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.7165\n",
            "Epoch 00150: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3343 - accuracy: 0.7165 - val_loss: 0.3674 - val_accuracy: 0.7187 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "metadata": {
        "id": "970mnE3diYsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8effbc74-691d-4d80-cc76-e5f19505636f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(np.sum(time_hinton.logs))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5801.244107889999\n"
          ]
        }
      ],
      "metadata": {
        "id": "wDjSa6kyxM5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91a89f95-7fab-4d98-9bde-1975b12d25cf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred = hinton_head(test_data)\n",
        "(loss, acc) = kd_evaluate(test_labels, pred)\n",
        "print(acc)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7187\n"
          ]
        }
      ],
      "metadata": {
        "id": "GtQ1t3pt0d73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df404152-af68-4ec0-d17a-2d30ee6d8a28"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure()\n",
        "plt.plot(hinton_hist.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(hinton_hist.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "�PNG

   IHDR  t   �   �fD   sBIT|d�   	pHYs    ��~�   8tEXtSoftware matplotlib version3.2.1, http://matplotlib.org/��:�    IDATx���y|U������ޛ}!���@"�����V�U[�uZmmg�c��T��:����l��j;�V[�����Hd�!Y����q/b���{�~>y$�or?��}���|�9�CDDb�'�����P����	��H�P����	��H��E�srr\III�^^D$&�\���9��ױ�zII	eee�zy��df;wLS.""qB�."'�""qB�."'�""qB�."'�""qB�."r�����סi�q��
t�#�u��������F��w�� ]��u��4w���M`[������װ��7~�η�:�v����`�����;���Ϳ]8��/ ��j�?��ӛ��J*�|~NwkH  @�x6�F���Bf�/�J��)w�x+4�u��tz�i���ާ���'�~��a�r�q�,ZO,�={�ӥ�"r"���E{w�����?��b}U3on���o��쎿q�w3�d��y��f�m�=_�����"�#�2�t^�BG�^>�}�K�+h�f�l�=)���F�Ώ�hH*&�_�/�Eפ��p���x�G����J���>�)�E$�BA��]{���HM�R8,否�A���f]U3;��3#��ԾH�-�3�Z�٣�Cܿt;?yq�� �S�0&i��t��L ����V�=?�y|xB�C^�?u	���_��Ɏ=m���	e���7�)�A�*�`�R�~�K�xL�x����"2h�B��{�3<�о��$�y�b�����-,-�s��W&��Y{��3v�%Ҹ���P˙ʪ�s��}�d���k��3�����<�?�ݍ�Z��˻�bD˦CjiO�%�9���x�<c΄k�y�rZ*V1*Ç'��^	��}�s����g���9��^��Ώl�yι����
t�Q��mP0��Q���طk��|���;��v�[`˳��.���=)���K��1��SB�iu)�q�,��.�i�|朓���M���U�8U�P�&�V\J9�G�Y�&悄������
�Z�GfV=����T��BA�&Fvl�p0b��5�l�=�Ꮶ�вr&�AR���ۣpL�nf^`pP	� �q�m8L�[��ι���*�E� �u��K�����&��sp�o�o�n�<7�b:������g��w~L*^��D:�Ƒ1z:����� ��\Z<���&����<�,��uF�2�k�����I$ny� F�����
�p��EO�Ps%��G������O~�Z��Ɯ	�WO�/�;�@��霻8�}�si��O�܋��s�"�}/��3��'HL�M0 O�+�y���\6�^Br�vJ��ѕ�O�k���%e�����ֈ�ٜ4���787������#���{
USnfTfm�Ԕ���k;�}�I���.�A�XF>�~fg�����%$��wp*�;�����Pr6�|ix�9������\$�$���?�G=W�W��� ���s�f�f�ѣG��DDz
����D�s��g�#�M�����OȽ�KHH�����հ�eJ�$/s%ns[_䂶�'�CqR�n���O�&��|3Y��1�+!%�ǜ��:����W��܉s+�����g����7r<����^.g��6>6�������5�4w��kg�KNz��q�7`���)�����oq��џ�U��ܧ#۟Nw���GۯEι[��������o�)�� ��<
{��{�%0�j7��رv)]��s�u����]&]�w�S��!�����\:I"�{	��<�0t-I��9%�t�C��ť�2��Cȼ,-o�U(.�嚳&���?#���s�`�����4�`r�#��@q���Ⱦ�,>����#�����'��!k����Th�U���t�����s���_����-�.1O�*}&�Y�SU�H��g�X�8ͤQ�r�b��[�-��x!t*7��W{���?�����
���IOb{C�����<��������M�eބs��A������Cs�-������p�� �uέ��n�P���tF#tt�P�2��P�Da��_�q���k��v?	�i�����Xˢ��8��>HH�'�wj܉/�	@Г�?	O�&��\�������#�5,/���IS8���\3)���?�3kkh��32�˧G�������Ş�.'y�$m}_��N���`:)	ғ���I�4'�i������jW��eX걭����e����#~�s��fvP�[is'�윻�?E)�%j�l��«#�F���;���`۫�F΢|ڿ3n��T��������lf��=\\w?c7�
�&�rɯ��圷�Q>�}��B��h��������Z:�O��颦3��$��_n�>@�7��|��K�y��'�`D���65�����)\yjg�����hWta�E�<G�$�ą0�"H΂��k߇@'��a��3�����б��#1��I2h��4�at�s�Ȯ�o����4�.���lN���M^�7aj�v#?M��M5mԴt2�0�O�S����8�x{g/�IZ���$>F�ᩗ�L�!�>O�|G �l��@���ո�I$yXnx�sд#�������E�3o��o�;C��^��?���b�J��S�_`|�K�����k��y40�����L�+|��,�5�po�ϸ�V�_c���x,�ZZ��0��!ƍ=���>�KOt���@���ju�d�����|+`��`J����p٥���J��QBxxm�ϙ;u#^�<I5o�Vb�Σ�����p�֞�e�]�5^�PAݖ���5���R�B!��8���O/�R�hl�&/#�d��&&fC��!wbx~==/:�%�]N4�~3�.��v����5��z�忁g���(>���fC�f��:3Ɛڰ�no*w�*�`���}�ad���G�g�+Yi��M>	�&P���i��<o;���IN������>�I|朓���b��s��ܴĐc]�(rx����ŧCR&����1�yOӐ/���S���d��gp?̫'��V���³����H8��n��iEV��	?��=� �~��1g�����;ȊS��"����IK��`�Q8,��g_������EŞ6.�\�YcG��z�^"qJ#t9(����c/̺!�v/���<J����������S�/��c{��к�5	�i�1��aު	���w.��Z�z60֪x(x!ߵi���a�B�`k	�ù挱L�I ���t�7���p�m��!��Ӕ�
��e���`�M�92��z�/�zu��ą��+`O����P�tmm���o�+��_%�3��k,���2�|ޭo;0ݑ�����8�t8��id%�X]����F�dsٌ�x=FmK����C�}(Ї��������=|��s�s��Ȭ��m���� o���
@�g^�i��m�m������]X(�}�K���EL9�QY)����/|(a-����;摑�ǙcG0!?��L/$7#�W�����̛��G��TH�z�i�	���%4�M�b#�/�hOD��Қ9[�c�ed,��B��̥bԥ��G{�>F�|���^�ή����?'q���XO-�f��~��jZ:��I,�Z���_���6N+�W� =I�cDN�`��5x���LJ�9���6-��=
�Yz�W9�rɝ�t�<s�t�D��E�K��ؼ������G£Y ���M�ԑ}�KOKdfq_Y0�	y���̻��C�Q�)�=.3����������;����ȹr��^"��)�������q�̀�j�"F�Lgj�^<e����C�׻L2���ݷ*:��K�1f2$���U<�z7�#��҇&0"!��/��(a�Y�Q0,�vx����#Aw��)
���k��^�����=w�ю�p����_u��E����Qd��^P�y�e��N���HNx�����5�Z[-��}����}7l����s2g����N��Z��[۰�\.��g1�8����3u�Qd�R�GQ���L6_���1����������L(���p.J��:�k]OS��C�\D�h)У�ond�����s�]���	z�!6�|�a�4�""C�/m���}Sxc��#"qC�~�u��|g�F�&��e��/� 
���/��ν휞T����\D��qαb��[�mn��FR{��[Dd@i�	�r�^���~�x��V�=>��� �q�cO7���+��3�S����$�~Ԭ?�MDd�(Џ��N?7���$��ג��3I8���L��<�q9��~�t/�����k���S���q�@?N�~�>U{7��$L�*�咳�]���1�q���*ڗ�G^B|�!(9;�%������}���ʞ}]|�+�5�iB%�(�E���X�Z�a�뭯�#�,~�E����Ztk�!E#�c�3_���������7�Ca��}Ɯ�
Ed��h9��j��տgo�h.��	_�gx���É�O
��Q���*W����t9��~m���sg���O��M�~4��/�\	��3��W��w��ӘV4,�Չ��9����l�������.~�J9�^Ȣ�FG�:��T�:pA9�=��;�ͪDD�Xժ��3Y[���vs�٥��J�n]"2��+��l��m6�r3��0m>nf�l��=<�e"U� -�`z!w>��i���yc�]��ȑO������V��b�܆m�w g9��,�xuU�`�LXV������d$'D�*�~��Oʝsۜs��#���|��9�����2��}а�Ƭ)����\8)�+f��vU""@�}���ved_O�	f����4�}� 3����̬�����*�����BܷuI>߹bf��DD��;)���� �5��ލ�s�:�f;�f����K�@�����M ?39���ԟ@���.���X��;�[||�Z�Odp�֜�� ӟ@_�7�R3K�{��+��9f�Cx
f� �9(t�\���1|�ܱ��_D�#�s. �<l��[ofw��e�f�{�l�
��ܞ�U�	
�o���}$5oc�o,ם�ѹ�>����sn	��׾o���_�|���7���K��o����|N��ѹ�J�R�p�v@�:���m�,}�U �}~t�9���X�\����^AI`+��<�K�Z����(�g���g���8oX-���u�"2H)��b)��s	�a~j9���A��hW%"rX
���TA�v�zf�>4��'���۠`Z�+9,�~��+߁m��?��y4�Ir{U��]D1=�n����k�O�O�ۛ���"&�Ɇ�B�hW)"rX�C��W�٥P8�W�24�3��1jzd�b�DHн[Dd�R�lz
j��y��'������M�|n:�2
 ���*EDޗ�\��W�9`����rk�ʹ�pބ�s:nz><#"2�i��Ru`Χ��ek�>ީl���F��D֜'��/1�u����as�s�d �][���F�"���@����;�g��0kt��R�X����@o��Y�����66V��p�F�"{��[�'D�X�nQ��H,R�7l��	8�xfM53Gg12K�-"{�v�w4B[�L���5l�n�YEѮJD��@����ǝ�7pra&��)>�7��NC;�#K�۔@mk'���T|ޡ�%"��vz�o������.�����ѮHD��@o�Bs�h�!��GG��c2��]7���d��̌v5""�d�z�n\��l�a��<L�
�74���8A_*O��`���ѮHD��@���7@�F�-j��;vD��9fC/��6�֗q���*�0oB.I>o��9fC/�k��:i6�-]\<� ������u������|d�&�`�]D�����������\5���M��H|�����6�@�q�.&�82��}/�V����7��rӣ]��ȀZ�^����Y4G�s�/C+�#+\��Ο��bDD�/��H�v=-d0n�8ғ�ԯ."C@�F�f���6�Y������̬��VG>>=��P���k�,�"�=�8t�a��y�{���J`��-v�m���Q��-ǡ�cS�~s.��o�F6�y,Խ[D$�g�~P����.?�e�U�.KIuЖ5����hW%"2��裀]=�+#�z���֘�cf��9��f3+3������(�
a�a�����_�����8��+"���)��97x�C_��s�:�f;�f����K��m�¾Z��q��w�xh�9��+"�	��@�wQd�ι=ι���}��S�1Z�'H�/f��j&d0.O�H|�O�� ƛY��%���=�Ya��ˀ�W�Q�n��O��R�e;Y8����'"�����90�[��/p�sn����9��ff�`/p�q����
�6�vϮ��9�"��uu�sn	��׾o������-��X�$(>�%ϯ�t��Ľ����2(�Mu[��n������
����3�sY% ���DD����]o�,��#o���9��E�*��*>}�`^��QBUs'מ�[�H���@߱
g�o�%7#���u����.�,c_�^�\Ǣ9�$x����-�����]���sp嬢hW$"rB��S6�|�<�P¸<�N��Ȑ_#�` �=��żZ�Ņ'�1s"2t�W�o{�X�5�@�1_��!$�}�!yj�DVj3���]���	?�����&t���n�O�ç�-"2��O�m}��Q�w1��~͟�Ȑ?���M�&�z�x N+�DDN��	��2(����r3���Ѓ�Edh��@tC�*(>��U-L��DDN���ڵ좻p����"2$�G�W��5i2��c��aQ.HD�ċ�@��d�dus�2��Ed(��@�\�sX_�LF�����hW$"r��~�遲�P4��U-�<2�Ǣ]���	���?��ͦ�VM��Ȑ��ް�
�:�A��!+�}�vH�a]�tBTD�����
^���}��G�"����@��%��jfb~��*"CVl�_��+q�%��_D�����]�B4%���W��Ȑہ޸�w�s ��."2��v����}٘�ɅQ.HD$zb;�+���[����Fj�/���DM�zv	�[tA��y��{�ӝ9���N��!/v�9h��>a$�F�"2��n����`|�����_�nf�l���������J3sf6{�J<��
 v���c�'��̎�f��.&ט��>�e ����>E֠�r��H«{���ן�i@�sn�s�x���v��t`}�����t�2�O�K��f�	�Q��ە�}��,��9���� 3����̬����{��F�$������t���1�53���Gj뜻�97�97;77��^��R��m��`�F�""�	��@q���Ⱦ�2����fV�,>�'F;	�d���'_S.""�
��x3+5�D`�x�A�\�s.�9W�+�.sΕ����h�;!��\�."ҏ@w��[�灍���s���.3��xxX�tx�7������H��f�[,�i{ޱ��M��,4B�X�R���&�W�*�EDb5Ѓ~�neO0���ɺm��HlzG u�
2�1�U�""1� Tw��*Q����]�ɚ?���@�O�T�%R�%�""@�zd�^L�]D$"��ɥ+�ED"b6�F+�
t�����Bxtٿ�HD�z�/|c���(#"28�l��1Wj�7�ň�1���L�||���DDZl�aG#��NZ���""�_�z��Nj��[DD���@����&�NZ�F�""��^�w�����HK�]Dd����U�{Ci�C�!f�!��9t�b6��)�C�!vݟB���ED��@���h]D������K�!��)�b/���+-_�ďO'EEDz��@ڻ �r�!&��+���������H��ry�����#t�C9 &}�=US.""�d��wk�."�[L��U.���������F�""��d��w�h�^���f���6�Y����ǖ���  �IDAT�ϙ�Z3[mf����/���,���r�@73/pp	0����~�97�9w
��'^i�]A]%*"�KF��ιmιn����s-=6� 7p%�W[w@W����ҟT��]	�޻��}��\0 �F{wP��e��*:��q΍�
|��6fv����YY}}�Q�־.��EDz�O���{lE��#�G�:����97�97;77��U����EE""��'�W �ͬ���E���l|���\��9t��:b*:�fv�<��wέ7���2��b�3���F���Y���EDޫ_�\��`I�}����m\��j����{�ܥ��`��@H�q�%��MwZ�S��-"ҷ���wZԥ�""���@?0B����!b.���5�."r��t��ED�s���k�IQ��EDz��@?��h��EDz��@��ED�s�>zx*�L-вE�^bn���)|hJA��tbn�.""}S����	��H�P����	��H�P����	��H�P����	s�E���G��9@� �s<�Ɓ��`�q�����1ιܾD-Џ���9�fG�����j����^�F��r�
t�8��~o���80T���5�� j��9ty�X���H/
t�8s�nf�l������Ѯ�̊��3�`f������f�������:�f��̞�l����H_>jf�Q�/��3�Mf�����>�b��:3���%G���~3�3�u=���o��H�k�lVk�a��3{�̲z�#R�f3�8Z5�8�e3sf�َJ?IL��y�{�K���5f69�U �윛�|>R����ι��ˑ�h���c����ιq@#pST�:�g�sιI�µ�>4�Q����sS/����������.�G>n~�_�:�[�; "�E�����*�ޏF��Y1�!`g������看�`.�|��;�;�]Wu>	\l
#�
��Q������i�_���o�P�0`;��=��>��~|���Ń��`ݑ��pM_�Nt���}x(��!�k�y`n�j#<�� r�ݏ��S#t������4̬�	,�sՑC5@~���)�@(�=hr�"����R�x 2-t���1���9���Z5��dp��~�����x6������.v;���uh���S���ff��_�/8�Zzs�?�QY#jf�s+�����f�v����5��>��C_N���H �>��>�D�ߎ�̾Nx��h�ғ��_��Z�+�}7P�c�(�/��,�p�?�{<����
#���(�wp��U ��v��ef�H�h�e%P�[�~�p��>�lw��;�����v0��~��A�2��� �E����q,�?��D�;E��fV�����+��U��O�,�rM���6:�~���b������[?�sw8犜s%���oι�W���]�s��ef#�.60H�0b'p���F���q��c�����"�4� �{L͜Pf���4�eι����,��J	�x|�D��[��sΕD�;���������I��8i�����ף]O���	��v�:��<�����K��AP�y�ӑ�O"�F)�$E��S��H?��l}��	X<$E��?������o�O��y��%�b'Z5�����������q3pI�j�u���'E�ҏG�Х�""q"֦\DD�0�""qB�."'�""qB�."'�""qB�."'�?�Ú:���    IEND�B`�"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "id": "hqU7bBcO0wtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9a87f2af-68c1-420a-a08c-422dca11bb0c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure()\n",
        "plt.plot(hinton_hist.history['loss'], label='Train Loss')\n",
        "plt.plot(hinton_hist.history['val_loss'], label='Validation Loss')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "�PNG

   IHDR  z   �   �-�   sBIT|d�   	pHYs    ��~�   8tEXtSoftware matplotlib version3.2.1, http://matplotlib.org/��:�    IDATx���yx\�y���=3��}_,ɖ�l��,aC�I�R��JB�&MM��$i��4;�� &@!L�b���]�7ɲ$K�vi4����sd�e�cI3ݟ�Ks��[��}�yV1Ơ�R*v�"�RJ�ѥ�^)�b�&z���q��R*�i�WJ��t Cegg����H���R���k��7���-�}YY��ՑC)�N+"��X۴�F)�b�&z���q��R*�i�WJ���^)�b�&z���q��R*��L�����'/oeݞ��E)��J�$����+�����E)��J�$��x�ɷ�/�H�R*��L��z\x�.���E)��J�$z��x���+��1�蓼:5�+��b*�'�{��Ӣ��
S�>1�M�_��R*TX�^D���������"�QD6��c!�Dd��Z6R�'9^�n�Rj�N<""n�>�R�X#"ˌ1C����1��ܐ��1Ɯ1�q+�롩�o,�J)�N���/ j�1��?��z�>_�3� 0�4�l��I�;z��:J8����\�5�,"o��jY��'"���O�"r��Ouss�I�����^)��2Rs�z�J��x]Dfc�1�"R�*"c��l�������|� ��ՍRJ%�;�z�$d��Y�Xf��7�� �b?Ƙz�g-�
8�c^g_y	W�U��Q�
��:���� �"R."^�`h�g�w�H6�(�VD2D$>d�9�FF�7���Fr���UJ�'L�Ƙ p�����AD��%�n+���|��L�E�g����uF�7��;���rz��
V�1f9�|Ⱥ7�7�W�>o�N=����g���K��Rꐘ��� �mb��R!b*�2ɔ���F)���DObthe�RJ���D�J�"S:��2z��:d�:LEwr6��MOoO�CQJ��Sw�q)9 :["�RJE��J���l��[�RJ��D/IY�gwk�#QJ��S��D��]=��RjPL&��>M�J)5(�}B& ^����R�#���K�$� ґ(�TԈ�Dt��H�o�tJ)5b.��x�I�D��R�b.��z�I	j�WJ�A1���q���H���RQ#�}�ώI�yc�R
b0��2I�>��:#�RJE��K��iK����H�R*:�\������H�R*:���Ed��l����\/"Ed��<��f��n���ŝdG��w���RJ���	'7pp)P��eƘ�!�Tw�c�H��>�.P`�s�u]u;Ct��RJAxw��cL�1�,��ϗ���1f���r�ecL���e`�Ȅ><o��|�t��RJAx����\�5�,"o��jY|ǎ����L�ν��5J)u��9c=@%pP�."��=XDnn(--=�@}q�2�$��<��QJ�X�}=P�\�U,3��cv [��?�c1��o��2�T���L�GI��c��'�s�)}�RJŊp��RD�E�� ,�ϳػyD$[�S� .�� .s֍���w!�={ ��c�R�E7Ƙ��܁M�n�!c���6�,�pB� �2ƴ �����{�1�>�S[b)q�~��iţ�uJ)��*�7�,�Y�������z�C�C����N�n�e�&z�Ըs=c$k�}�Z�@�R*
�d�Oʙ@���߼=ҡ(�T��d�/�Hb���ߴ5ҡ(�T��d�/J����C�H���R���0=�&_�.mb���b2����M�`t4D:�����L�n�О0�.�j��Rj|��DH/�o���Rj���D�YB/^h֖7J��-f}AF[�%�}F:�����M�E	l��DoL��QJ����D_���FS��� �52�RJ�1����tZ�h�Rj��D_��c�)� ��H���R��>�GBr-�Bط>��(�T��l�����ʵ�F)5��|���-�;��=��(�TD�t����º@�]h��`�R*Bb:�O�Kі7J�q/�}2�d��5�D:�����N�)�8��y;������J��'�D/"�Ed��Ԉ�]�l�ED�Ed��5d�@��e#|8&�%���`��~�X�RJE�	������+����"2}�]�0Ɯ�Y��~�Ȅ���)��%S�����{��w¹�_ �cj�1~`)p��5r����4�zh��ݫ#�RJ��p}�'d��Y7�5"�^D�����>���"���@Dns��nnn?�0L�K`]���M��0����R�n�*c�ʌ1����GB�M0�T�~&"�l���Se��������I�ɸ64�t�|sD?_)��]8���C/v�b�i1��9� �B��;?k�U����I�Ź�����{E�t��eJ)Q�$�5@������8�����,.69�3D$�y���y�噼�� ��v�-�WJ�'L�Ƙ p����`�� "���`+�;Ed��| �	�⬟T;�_�5ƌy��_�I��M2	�^���X���R�	g'c�r`��u�	y7p�0ǽ�:�Oق�L ���ͬ�y�K�Rj��鞱��R}�f&�fg���mX��H���Rcb\$z��7�;`Jς` ��F:$���&�/(Ϡ��ώ���h�Rj�7�~~�SN�0 �U��ڍݭ����Rj�D_��DNJ<omo�-�����.�����Q)�FEX�nb��p��^ڰ��5K��ۿ���;!�w��PJ��Ѹ���xj.��ޫ;�l��/:l�RJŘq��ϭ�&�-����n��$Ĥ+lwh�� �Rj��D��cAy&�mn�����7��1p@'WJŤq��.�����N��vCٹ�?R� >�6E:<��q�.�_45�׶4^)�ӠQ��R�g�%���d*r�xa����s�٢�jP)c�]���E�����ʝ��c_�SJ�Q0.�g�#O�Wwxe�4�S+d�R1f\&���Ι�����:E5��V�*�b˸L� ��+fOk��t:I%eCR.�z�구^)3�m��|F>���ZR|S\[��O�Ó�D,6��I�6�'x�,��ϊ����?`W^�|�O0�"��zdTJ�2n=��9�t�X��ٮ�K��d'^=�:��R*&��D��,���<�~��&ٟ-5c�RJ��q��=nW�*`�F���7dWڟ��R1 �D/"�Ed��Ԉ�]�l�ED�Ed��5d��"��y�<����%g���卍�W������E.0��!'L�"��� �7���av}�s��z�96�.�X |WD2F,�0�4��4�}R|㎃�r��WJńp�� 5ƘZc�X
\��_�l�i5� ^�PG��%\5��׷5s��xC�$M�J��N�/��,�9놺FD֋�S"Rr2Ǌ�m"R-"����a�>r��]H���ŏBƹɞ-�O ��R�����}(3���޵?r2c�7�Tc�rrrF(���,J�<;��⛬J胶=�>P)�N�$�z�$d��Yw�1��38����p��"�U�x�����^�R�X*�bD8�~P)"�"�n ��� "!�K����V ��H�S	{��.�\5�c���q��ibi��])���	�1& ܁MЛ�?c6��="����N� " w�8Ƕ��^,� �8�Ne^
S�Sx�}�#)�N/x�D��#v\����	R)�>O8;c�ˇ��N������q�C�C�㘹����?���{ۙ^�j�o�ז~�[��h��3+�.P��:	�g�P�=�����5�튢�vp�M�����v�I|J)�qh����劙�<�~==���{6�?ylz��1���}ߺ#�*�Tx4�q�R:z�R6>nz
���-����BG��RQL��3��Nb�N�MB:|�E����³_��vh�l����R*zi�BD�aA	ջ���î�&�����3`+a��D_�ZwF,^��:M�øfn1qna�CzŖ,�v��&��B(�c�nt�Y�T��D?���x.�����_wx�A�8���N�ϝ
e��ū�Rǣ��n�_���~Vl�w䆊�i4n�'уV�*���&�c8{b���<>X);��|�3��$�r��M,�RQJ�1�\��UŬ�mewK��s��n��L��	����+���&�����bDੵ!��.7��g��L��H)�&�J�����8
�8wR6O�WO0Ҫ��;���m����kэR*Ji�?��J�?��[�CZՔ,����rF��(���&��lz�>O�=�LSeб����G)�"D�	���|��"^�p���O�;��l�4�v��� M�a���
�ᷯ��C�l��a����Ra�D���D��Sȣ�즵����lT�4�+���&�0}�������ô�q� ���+���&�0U楰xF>�����a�͟��$J)E4џ��\8��� �_����!�s��ĕR*4џ����W�̓o�9�%h��R*j���Ed��l���8�]#"FD���2��u����T��rǅ�����5C���Lw<�� 2�)��1�0ы�����("Ӈ�/�:�ΐMۍ1g8��G �ZP�IՄ~���G�ջ� w���+��N8w��cL�1�,�f��?�ѫ(6�߸t2{�z���w��`�mbF"4��V8��-��s�""s�c��_."�ȟE��@Dn�j�nnn7��9{R6L�ᗯ�p �]}�"�9 ?�	���8J��pʕ�"�~|s��@�1�L��c"�:t'c��Ƙ*cLUNNΩ�4&�b]}~�jH+�97�5���U���;� c��nlUJ�{�$�z�$d��Y7(�	����Y�2�2��cZ �1k����<Ҧ�p}U	�[���8"0�Z��);���_yЪ{�3`�kc�Rj�
'ѯ*E�\D������Ƙ6cL�1��S��c�E$ǩ�ED*�J�Ɯ~�r�$A�#o�<r��o�=��~�]��o�����[^�8�R��	�1& �� 60�l�{Dd�	��^D�O�cZO5�hQ������y���t�Gn<�&��_~/|^�G�r%T\�zG��;a��c�c&c&c~���1f�0�^`��v�?m���4��k�yn����/}����~�^;��ݗ
g�5l~����µA奰+<���J)5��g�)�[��%�<��C�U��X�e��������m��A�k��y�QJE!M��HD�����l���!w�ɹpŽ�7���i��o+d_��-�y�_�6h�Ը��~\>#�e���K[ind�P"0�B[!��/ 1�=���M�J�qG��s�tt����0vŅv�˜�p�k�I��~8��*��%M�#dfQ��+��v�����;O��-����RX�U���ywLbUJ�/��G��_6�K���[��cB:���ly=��w@Z	<v=��h�UJ�+��GPn��ϟS�?��ƽ���K����"���Z��^�J�qG�����������O���
��y�k���JlJ��I�KK���L�-ͼU���Κ�g��գ�Rj\�D?
n9�����y~#Asr�.���C����w4я_���r��u=���L8���CSJ�S��~�\9+��D����IN�d ���Q�M)5�h�%"�w�L��7���w�88ǒ���a�[��Rj��D?�f�����͚��œh�3a��<58�J)u��G��U%�rv���W66�wP�"�wB�v�RJ�:M�c�۟���d��l����t�����`\)u�<�`<�s����gq�o��+k�늩�? ���
��/�h���a��29׎c߹�ɐ]	ٓ�+��Nc��R!4я��\7���R�g�19/��,�w�ėj^��Bpy��<�}������L����)'(��6[����ib�Iv�eUUU���:�a���.?��*&���ߞ������} .{'?��6�_��ۡ���0��w��y3m�O/_��8�x��9�l��(;���F�VJ�Yk��v�&���Ě�������溪�����x�vس�l�n�1�)̟ӯ��l��}B�q)�Mc��!}�C������ZL�T�8�D/"���n�c̽����)`���"r7�E` ����x��>4\����m�d�7/ 3�;z_f�}"h�f'#�k���(�	��2�����s����q�@������w}������0�*���;�;�Zl%���!ש��m��	.��Wj��R�7���� 7c6�/x�wc�Ed:�8� (^&c�ٔ$�=��}�,�՛�Q��￸�'
`{�_j�r0`�t�S�il[-56Y�w�$���p.̺�^�����_���R���pp<���p�c���(9�D���1�rg�n c̿��g������w����
糎ٿ<$z�?����K�q��b~|�����#e `+}�����8߾�����U\ s>g��KB�&{��m��_����X\���)�#��J������iuS���U,�s�c�"�!Ǯrl�0��PZZFH����(b��.~��6��p�y�����w�}�}=L��}��"��Hʶ���a��CR|�5x���ίm�P��NB4����Bg�}2Ȯ�Y���O�	Y�A[�\_�}�?a?�6x����'��[_���+�c���R�ܼRD\�O�[>�gc��{G�1�.�~q%���?mf~Y&sJ�#���&��p��
q�P<ߎ��������>�<>���;4����ܝ��?��_����Y�O�G���'d�
a�2&���	��3`��nY����r�rэ��ہN�|�X�-�ע��8��瓿x����y�%�E:��e�a���!���
]c��=x�'��y����/����w��=���e?��?p	t셲�l����M+�O%a�ŶSYr��6�,�O�o�i����Pj��j�[{1P�����1f�1�_��2��c��]	T���ء��j�~��酩��-��J��tHѡ�=[�[v���k�
����f/�^���j����?�o�u�Cz	��l��'=�X��,h��O�����2�m'��i��O'��#�+u�F�y��ϰ�+2��PD���1ˆ�
'�;��� ��3Ƽx����`�F���{e$����"/�w�Tx�:�h�v��]�%P�~[0�zx����yL|�������7<
�����j�Fz�����6$f��d��c�a�4��V���w����|zV��?����������lO��Bx���~�4{�*k��h��[{��נ��m�����p��n\o��Vj�ςO|�Vr+u��O#��u����w�����<*���s_��f_o���Sm�Nb��o߇��'mS��ٶبadU�����οy+��Cg# v������Ϗ��ϫ�|�Ǐ�i��O+>�	N�;�ڼR���Jx��z^�����-�t8
쨠7?w���g�_�m�KϲO
��w�+������JaO�-�ɟe���O�\󀽋��_�Igا���u�0�"X�mۤ���O¼���<�'�[P���Gc�xy�>���E�G���Zh�����7Im�h��������v���3���k{(��ڊ�>[T�Qf����G��:��Ӯ�O��p�����4�_�j���«�<����H��"��N[�S4*/�}�6=����+�ttPo�]߽ߎs����n!k���d��ܛm�֗�~���6����j�h�?�4��r�^#����Eeܰ�D[ᨏ�q����N w:ԭ9<Ee�[,ձ�65��!�y�~j^�-���E���$[��OQG�i����ի5������������K[O?]� 9���*NcVQsJҙQ�J�W�]�qc���^�_@���ػ&_f���Ŷ��Ag��3l�Rv�������e/*�J�fXp��b�}�IV%����ߌM����͝,_��+�0���2�H�z�{����hh��%P��¬�4f�qfI�Sq	�j�&2)�3[��� ��l��y�<\���cn�����m���,�ﵕ�= '�$d�Ig��0�}�YS��  IDAT���~�4���,�.�ۋ����8I�;JjJ��o�c���o�=�/��k�f(M�1������X_�������k���@ZBI^7{���ESs���"Z:�t�(�NbFa*%����T4�l�E<i'h�U�
���}��ڤ��og3˟�=�g������T<��+L������Q�Y-g�*����������S���'��r��������O'�k�-�*<��]�M��1��m�T�l�͚�t�8�"��n?����z��:fzA*�Vf��駭�OAZs��bV����/�}	>�#�V&�����pΛ�|����G�o�}2����A�"i�[��mE����R[ќ^
g��}"x�v8������[I��k�	D\v�+�r�;��?��_���b�b���!�}j�;�O�禶��5;[y���׵��OZB�{����_�Io� ��~ʳ��U�ʬ�4����`g3�R�M��A�߁���I��q��0���1��;L��l�R�\�a��n;vW3L���l�Q�l;�B�z�~�^.�g[|�{��e{(��c��>
7=%���4�K�
�1�	Pv�����=�����D/i	q�4u��������oD�̒t|qnv�39/���2�$���<�(�EK�~z��ǚ�����o�3�>��.�����;���m��Κd/g}������;�T�d!\�Cؿ��[W���θ��Y<~�}��w�}�ȟu��5ѫ��?���v�5v��GzBo׶�jK3n�������^����$&�&3�0�3J��I�=6�|��b|hf5v�]�sY������Җ�p�@R��h6�:��tZ��g�ۼ�>AdV��+m]C��4Ѷ�N�986Q�����]y3�8}�Ǵ	ڋ�L���^��`а���M��4w��y���}�~���"�YE�&xH�ő��`4w�����g'1�4�+��T�h�5+m%m��c?At�ډs6� ;^�Iߗf����v�����H�u�Z"�Ңq�3�v�iW�y߰��>&M�*j�u���� m=��m��MM�l����3��\8%�E���I����c�hj��Pc��Ͷ@����Ȭ�-��߳MLs��Ni)y�d�޷��O�Ep�=v@���W_�}B����b!M�*�c�i����'�d'��q	-�~>�ocņ}�e[3��l5����lz���2� ���$��{ih�%h��⓳
X41+�'bW�So�y�6K������U�[�:�k�� �GGo�'��X�����8\"l��No�@n��Kh�駳/@qF^���f�q��,�.��7���Vdj��:-�0�*f�\���T��ZwVő���4u���O��ڧ���7��G�����z\�����76q��%Td'Q�����M�br^ʡ�Q�t�w�j�2���֋�-$z=��;���-l����}�n��.��Ts�ӹhj.�� kw�?$/�G^j<y�>&�0� aOk7qn�iڷ@�-�Q�chh�aum;���s��������%��O��þ�^�����O��s����8�p�y�yQ���F�&z�F�1�-��<n&d%���������v`Ֆ&��9�������߫��qQ��@vr<ƀ��fj~
3��XT�����wvS����\<-��9�Zi�N�&z�"�zg+/mldOk7-]~�b+�k�:��z\�A�3�;����D�&d������^*���V�Jaz�)����K�''9^/
��XY�pc���v�� �	�f��("e�&`���jc���P�tTU�IUY�Q���ljh獚�4��q]U13
��{�����xuS#��4Q��Hen2;�w���&��<Af���Ei�.JcfQ%�	�$������_����x�R|���ٸu�;zq[�K�:`p�1fc�>�Ƙv���+Ƙ�N��33܀�^���A�w����Gc{/{���·��lm�8j��P	qn&�%���#9����dM�"=�NfS��@y�0s٪�Ʃ��/ j�1�·-�%��$�H�~�J�S���(LO�0=�m��l��AC[͝~����$���������.�6ږD������>��s������\�ESr�|f>iG�:���苀=!�u�¡;��W�o ^࢐M�"�>���1�/�{p@iii��+�,_��9%��)Ik���>���Jo� ��>��:��V�b��������6r���xZMͥ�/��N?{t�r��ί̡$3A�	�\8E7���1�:�,4��q��?\n��YD�dcL����fy8��(��a��C��j�;yjmK����4�-g$�?<Tq��"�dz˳hj凉���&�u!�������4�8mv:RN��(	Y.v��R�� Ƙ>��y�VD����JE�Kpq8!W�$�����K*ij�#5!��x.�`�a{s�k[����{����e��-�LdQE͝}lo�dOk7As�r���@�pٌ<n=����b����� �"R�M�7 ��AD*�1ۜ�Oۜ�9@�1f@D*�J�v��WJ��x���9�E�I��L�=<A��d�E�	��Sw���{�xus/~�@AZ3Ӹ��"�������}�����5<��N�R}t��M�15/�)��_�/������Ez����~Vnj���<�>�:a�7�D�`�y�CƘ"rPm�Y�!"� ���f��O ��H?n7ƴ��/������y�>�M��o��u���m<��z�H���`/oj���U���^�A:z ������O�̢T��3��]^}�x���RQ����-�:ؼ�6#������� ���N2�bV��8ެ��}�հ���s+s]� =���Wr����r�J2I�����g�Rj�h���?_�»;ZI��I�z��n��t�F�~S�/΅�mG4�s��Ź�J��27�i��/�$3�{���c9�t�b�Ը���=W��fC[�Զ���KkW��@��@���Z:�|T���]&�&�v��?@k����~���g$r��<��WLW_��um$�{(�I�<+)*z$��RJC�?���vV׶�n�A �=.2�����h��ckc'kw����d�|�D������ >��[q�mvj���/���>��ʼ�����+��ǐ��0oB&�&=^Q���N^X�@NJ<g����`SC����o��a�I�yH�����?T�|fi:�|��=�^)�FI0hxk{�}����z�Av�v�ao;�@���x���d%�b������WJ�p��s+��Z.G��8��۔RJ�9M�J)�4�+�T��D��R1N�RJ�8M�J)�4�+�T��D��R1.�zƊH3��>"�?B጖h�1���q�h�##b�`��nC�%�S%"���-�=�h�4Ƒ�1��h�Q�n�R*�i�WJ�����H�h�1���q�h�##�c��2z��RG��;z��R!4�+�T���D/"�Ed��Ԉ�]��@DJD�5�("D����LyYD�9?3� V���/"�;��"�s>�o��K��Dd��l�E�tE��8�����"⋆s("�H��|�n��&�/�x׋����ο�zyFD�C���ķED.���cȶo���lgy��a8b"ы�����("�# ��Ƙ��Y�W���Vc*���r�}���#�ƘI����갟2�L�`c���("E��@�1f&�n :�����!�uޮ *��m��#���Lc�l`+p7��s0�9濜��HĈ�� ��CVG���1���!�wwG:�a��#p)�(p� ["W1��"�y@���<Ý�ė��i<�>*�#P�2��s>\-�(>:�y~�8�~cߐm�u��w� E�:���t��#yO�;z���s�E)���1Φ}@^���3�����4���H��r��o�x�I"JΣ1��1�ήh�]�0Ա�[4�}x�y5���@�1�!��&�P��裚�$Og�i�f�e?bm\E�S@�1fm�b����s&�Őb�H�G���j��Hb�G�h���#"��>�XB�H"�O�w"K�b%��%!��κ��8l�����F)p� M��8X"";���⛟�"�q������1�8�Oa���K�ƘfcL?���M�0Ա�[����-������DO|�����b�=�'zb<B�$�5@�������Y�6c~�ip���fl�}Dc�6�cʰ��Uc�M�k���n��q�GD�8�.6=�q7p��$:���E�9�X�m��9-G��B�xƌ�,�%.1�t�lZ� "�"R���|w��3�|h��5Ɣ97u�\��iT�ãD��`+K����o��x����>��9�+�e�+�m�+@f�cu� x�y_��#���#�@�s.�2��<�
l>~�G�9���c��uް���9Cb[E"�l9��������N|[�+"u�l�����1?��t���q�Rt��R�4�+�T��D��R1N�RJ�8M�J)�4�+�T��D��R1��3�H!Kg�    IEND�B`�"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "id": "2EbTR6hk1KVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c137bb6a-ac83-4200-ead2-fa5bc250ab31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hydra Weights Initialization"
      ],
      "metadata": {
        "id": "7EGj8kLSuTX7",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "hinton_head_1 = tf.keras.models.Model(inputs= hinton_head.input, outputs= hinton_head.get_layer('soft_prob_1').output)\n",
        "\n",
        "\n",
        "body = 4+(3*int((depth-2)/6)-1-2)*7+(2*8)\n",
        "print(body)\n",
        "#head = body+11 #for training with ground truth\n",
        "#head = body+12 #for training without ground truth\n",
        "#head = body+19 #for training without ground truth 2 res-blocks per head\n",
        "\n",
        "for i in range(body):\n",
        "  hydra.layers[i].set_weights(hinton_head_1.layers[i].get_weights())\n",
        "  hydra.layers[i].trainable = False\n",
        "\n",
        "count = body\n",
        "for i in hinton_head_1.layers[body:]:\n",
        "  weights = i.get_weights()\n",
        "  for _ in range(4):\n",
        "    if count<len(hydra.layers):\n",
        "      hydra.layers[count].set_weights(weights)\n",
        "      count+=1\n",
        "\n",
        "\n",
        "for i in hydra.layers:\n",
        "  print(i, i.trainable)\n",
        "\n",
        "\n",
        "#hinton_softmax = hinton_head.layers[head].get_weights()\n",
        "#hinton_softprob = hinton_head.layers[head+1].get_weights()\n",
        "#hinton_concatenate = hinton_head.layers[head+2].get_weights()\n",
        "\n",
        "#hydra.layers[85].set_weights(hinton_softmax)\n",
        "#hydra.layers[86].set_weights(hinton_softprob)\n",
        "#hydra.layers[87].set_weights(hinton_softmax)\n",
        "#hydra.layers[88].set_weights(hinton_softprob)\n",
        "#hydra.layers[89].set_weights(hinton_softmax)\n",
        "#hydra.layers[90].set_weights(hinton_softprob)\n",
        "#hydra.layers[91].set_weights(hinton_softmax)\n",
        "#hydra.layers[92].set_weights(hinton_softprob)\n",
        "#hydra.layers[93].set_weights(hinton_concatenate)\n",
        "#hydra.layers[94].set_weights(hinton_concatenate)\n",
        "#hydra.layers[95].set_weights(hinton_concatenate)\n",
        "#hydra.layers[96].set_weights(hinton_concatenate)\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "DLkV_aU1mS7o",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "filepath = ('model/hydra_cp/cp.ckpt')\n",
        "\n",
        "hydra_cp = keras.callbacks.ModelCheckpoint(filepath, verbose=1, save_weights_only=True)"
      ],
      "outputs": [],
      "metadata": {
        "colab_type": "code",
        "id": "ZJA3-xKEAFKx",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def lr_schedule(epoch):\n",
        "  lr = 1e-3\n",
        "  if epoch>=50:\n",
        "    lr*= 1e-1\n",
        "  elif epoch>=100:\n",
        "    lr*= 1e-2\n",
        "  elif epoch>=150:\n",
        "    lr*= 1e-3\n",
        "  return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
      ],
      "outputs": [],
      "metadata": {
        "colab_type": "code",
        "id": "vAOGQ6BCAFK1",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=4, verbose=0, mode='auto',\n",
        "    baseline=None, restore_best_weights=True\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "afDER_DOJ4Nx",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "class TimingCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, logs={}):\n",
        "        self.logs=[]\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.starttime = timer()\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(timer()-self.starttime)\n",
        "\n",
        "time_hydra = TimingCallback()"
      ],
      "outputs": [],
      "metadata": {
        "colab_type": "code",
        "id": "kUl_0v38AFK3",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sgd = tf.keras.optimizers.SGD(learning_rate=lr_schedule(0), momentum=0.9)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mJPR8NBANo3c",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "hydra.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 16)   2320        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 16)   0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 32, 32, 16)   0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 16)   2320        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 16)   2320        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 32, 32, 16)   0           activation_18[0][0]              \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 32)   4640        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 32)   9248        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 32)   544         activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 32)   0           conv2d_24[0][0]                  \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 32)   9248        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 32)   9248        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 16, 16, 32)   0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 32)   9248        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 32)   9248        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 16, 16, 32)   0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 64)     18496       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 64)     36928       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 64)     2112        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 64)     0           conv2d_31[0][0]                  \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 64)     36928       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 64)     36928       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 64)     0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 64)     256         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 64)     256         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 64)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 64)     0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 64)     36928       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 64)     36928       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 64)     36928       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 64)     36928       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 64)     256         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 64)     0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 64)     0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 64)     0           activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 64)     0           activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 1, 1, 64)     0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 64)           0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 64)           0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "logits_1 (Dense)                (None, 10)           650         flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_2 (Dense)                (None, 10)           650         flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_3 (Dense)                (None, 10)           650         flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_4 (Dense)                (None, 10)           650         flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 10)           0           logits_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 10)           0           logits_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 10)           0           logits_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 10)           0           logits_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_1 (Activation)        (None, 10)           0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_2 (Activation)        (None, 10)           0           lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_3 (Activation)        (None, 10)           0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_4 (Activation)        (None, 10)           0           lambda_3[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 499,496\n",
            "Trainable params: 299,048\n",
            "Non-trainable params: 200,448\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "id": "Oyrf3w0ixpPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbdfc17d-6eb6-468b-a0ac-428b34d69b8b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "kl_loss = tf.keras.losses.KLDivergence()\n",
        "ce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "cos_loss = tf.keras.losses.CosineSimilarity()\n",
        "\n",
        "hydra.compile(optimizer=sgd, loss= [ce_loss, ce_loss, ce_loss, ce_loss] , metrics=['accuracy'])"
      ],
      "outputs": [],
      "metadata": {
        "colab_type": "code",
        "id": "DlLGuHrBAFK4",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "hydra_hist = hydra.fit(student_train_ds, epochs=200, validation_data=(student_test_ds), callbacks=[hydra_cp, lr_scheduler])"
      ],
      "outputs": [],
      "metadata": {
        "colab_type": "code",
        "id": "daqGV9DoAFK6",
        "colab": {}
      }
    }
  ]
}