{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hydra_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPzVnTnhHEt7egfCFEueS3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaung-htet-myat/Multi-teachers-Knowledge-Distillation/blob/master/Hydra_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfF18-BEWAXh",
        "colab_type": "text"
      },
      "source": [
        "Models to train:\n",
        "1. resnet20\n",
        "2. resnet14\n",
        "3. resnet32\n",
        "4. resnet44"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOBf9Dl2COkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d38c019d-b1a9-433b-80f4-9d1ce8ed9dc5"
      },
      "source": [
        "!nvidia-smi --query-gpu=gpu_name --format=csv,noheader"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHtnE3lBScnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import scipy as sp\n",
        "from scipy.stats import entropy\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from nets.keras_resnet import resnet_v1, resnet_v2\n",
        "from nets.student_model_multeacherKD import resnet_student\n",
        "from nets.student_model_multeacherKD_wo_GT import resnet_student_wo_GT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg5ut4pXwyqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 6\n",
        "batch_size = 32\n",
        "temperature = 4\n",
        "alpha = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWrDB_QN15iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# js_divergence\n",
        "\n",
        "def JS_Divergence(softmaxes):\n",
        "  softsum = np.zeros(softmaxes[0].shape)\n",
        "  jsd = 0.0\n",
        "\n",
        "  for i in softmaxes:\n",
        "    j = np.asarray(i) \n",
        "    j = j/j.sum()\n",
        "    softsum += j\n",
        "\n",
        "  m = 1./3*softsum \n",
        "\n",
        "  for i in softmaxes:\n",
        "    j = np.asarray(i)\n",
        "    jsd += sp.stats.entropy(j,m, base=np.e)/5.\n",
        "\n",
        "  return jsd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEk4Pb7tltT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kd_loss(y_true, y_pred):\n",
        "\n",
        "  '''\n",
        "    Calculate modified Kullback-Leibler Divergence between ground truths and prediction.\n",
        "  '''\n",
        "\n",
        "  y_true_normal = y_true[:,:10]\n",
        "  y_true_soft = y_true[:,10:]\n",
        "  y_pred_normal = y_pred[:,:10]\n",
        "  y_pred_soft = y_pred[:, 10:]\n",
        "\n",
        "  t = temperature\n",
        "\n",
        "  #a = tf.keras.losses.kullback_leibler_divergence(y_true_soft, y_pred_soft) # kl divergence between softened logits of teacher and student\n",
        "  a = tf.keras.losses.categorical_crossentropy(y_true_soft, y_pred_soft)\n",
        "  b = tf.keras.losses.categorical_crossentropy(y_true_normal, y_pred_normal) # cross entropy between student's prediction and ground truth label\n",
        "\n",
        "  return a*(alpha*t*t)+b*(1-alpha)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oERzXqRKEHcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def js_loss(y_true, y_pred):\n",
        "\n",
        "  '''\n",
        "    Calculate jensen_shennon_divergence between ground truths and prediction.\n",
        "  '''\n",
        "\n",
        "  return nsl.lib.jensen_shannon_divergence(np.array(y_true), tf.keras.utils.to_categorical(np.argmax(np.array(y_pred), axis=1)), axis=1) # js divergence between logits of teacher and student"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv7h7aMkOb7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kd_evaluate(y_true, y_pred):\n",
        "    y_pred_normal = y_pred[:,:10]\n",
        "    \n",
        "    #return tf.keras.metrics.categorical_accuracy(y_true, y_pred_normal)\n",
        "    \n",
        "    m = tf.keras.metrics.CategoricalAccuracy()\n",
        "    #_ = m.update_state(y_true, y_pred_normal) \n",
        "\n",
        "    m(y_true, y_pred_normal)\n",
        "  \n",
        "    acc = m.result().numpy() \n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    loss = cce(y_true, y_pred_normal).numpy()\n",
        "    \n",
        "    return (loss,acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb1xe-taluIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multihead_kd_evaluate(y_true, y_pred):\n",
        "\n",
        "    #y_pred_normal = y_pred[:,:,:10] # (4,1000,10)\n",
        "    \n",
        "    #return tf.keras.metrics.categorical_accuracy(y_true, y_pred_normal)\n",
        "\n",
        "    pred = []\n",
        "    acc = []\n",
        "    loss = []\n",
        "    \n",
        "    m = tf.keras.metrics.CategoricalAccuracy()\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "    #_ = m.update_state(y_true, y_pred_normal) \n",
        "\n",
        "    for i in range(len(y_pred)): # 4\n",
        "      m(y_true, y_pred[i][:,:10])\n",
        "      pred.append(y_pred[i][:,:10])\n",
        "      acc.append(m.result().numpy()) \n",
        "      loss.append(cce(y_true, y_pred[i][:,:10]).numpy())\n",
        "      m.reset_states\n",
        "\n",
        "    pred = np.array(pred)\n",
        "    avg_pred = pred.mean(axis=0)\n",
        "    m(y_true, avg_pred)\n",
        "    avg_acc = m.result().numpy()\n",
        "    m.reset_states\n",
        "    \n",
        "    return (loss,acc, avg_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weoLNsmClwxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_softmax(logits, temperature=1):\n",
        "\n",
        "  '''\n",
        "    Annealing the temperature of the softmax.\n",
        "  '''\n",
        "  logits = logits/temperature\n",
        "  return np.exp(logits)/np.sum(np.exp(logits))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94RwbDyc3ffY",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft_d5mkfUcpN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a66f9f59-6051-472c-f384-44cd1853a094"
      },
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "train_data, test_data = train_data.astype('float32')/255. , test_data.astype('float32')/255.\n",
        "train_labels, test_labels = train_labels.astype('int32'), test_labels.astype('int32')\n",
        "\n",
        "x_train_mean = np.mean(train_data, axis=0)\n",
        "train_data -= x_train_mean\n",
        "test_data -= x_train_mean\n",
        "\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
        "\n",
        "def random_shift(image):\n",
        "    return  tf.keras.preprocessing.image.random_shift(image, 0.1, 0.1,  row_axis=0, col_axis=1, channel_axis=2)\n",
        "\n",
        "def augment(image, label):\n",
        "    image = tf.numpy_function(random_shift, [image], tf.float32)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    return image, label\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
        "train_ds = train_ds.shuffle(10000, seed=seed)\n",
        "train_ds = train_ds.map(augment)\n",
        "train_ds = train_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "train_steps_per_epoch = tf.data.experimental.cardinality(train_ds)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
        "test_ds = test_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "print(train_data.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwuMP_EPKceG",
        "colab_type": "text"
      },
      "source": [
        "## Teacher Models Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmw_mKVGKfak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1494d403-8850-4fbb-8497-c740a6ab62ee"
      },
      "source": [
        "resnet_20 = tf.keras.models.load_model('models/resnet_20')\n",
        "resnet_20.evaluate(test_data, test_labels)\n",
        "\n",
        "pred = resnet_20(test_data)\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "m(test_labels, pred)\n",
        "print(\"Accuracy: \",m.result().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5051 - accuracy: 0.8766\n",
            "Accuracy:  0.8766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAq0NKb6K1bu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20b292ec-fe52-4c8e-9464-84fb3e99bdf0"
      },
      "source": [
        "resnet_14 = tf.keras.models.load_model('models/resnet_14')\n",
        "resnet_14.evaluate(test_data, test_labels)\n",
        "\n",
        "pred = resnet_14(test_data)\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "m(test_labels, pred)\n",
        "print(\"Accuracy: \",m.result().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8612\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1VrUOpMK1ee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "51dab7a5-822d-4496-b383-69323811e274"
      },
      "source": [
        "resnet_32 = tf.keras.models.load_model('models/resnet_32')\n",
        "resnet_32.evaluate(test_data, test_labels)\n",
        "\n",
        "pred = resnet_32(test_data)\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "m(test_labels, pred)\n",
        "print(\"Accuracy: \",m.result().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5683 - accuracy: 0.8672\n",
            "Accuracy:  0.8672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FArETnucK1iI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7d56ab9-dd41-4927-aade-a59d9fb3bde6"
      },
      "source": [
        "resnet_44 = tf.keras.models.load_model('models/resnet_44')\n",
        "resnet_44.evaluate(test_data, test_labels)\n",
        "\n",
        "pred = resnet_44(test_data)\n",
        "m = tf.keras.metrics.CategoricalAccuracy()\n",
        "m(test_labels, pred)\n",
        "print(\"Accuracy: \",m.result().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 0.5796 - accuracy: 0.8735\n",
            "Accuracy:  0.8735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYxebEcyl-C5",
        "colab_type": "text"
      },
      "source": [
        "## Teachers' logits extractions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFsQY9ggsCfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_labels(model, data, label, t, g_truth=False):\n",
        "  model_sans_softmax = keras.models.Model(inputs=model.input, outputs = model.get_layer('logits').output)\n",
        "  new_logits = model_sans_softmax.predict(data)\n",
        "  unsoftened_prob = new_softmax(new_logits, 1)\n",
        "  softened_prob = new_softmax(new_logits, t)\n",
        "  if g_truth:\n",
        "    labels = np.hstack([label, softened_prob])\n",
        "  else:\n",
        "    labels = softened_prob\n",
        "\n",
        "  return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yH9S6zWeihr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "513ac356-e3a7-4163-e9e1-9b2fecc510b4"
      },
      "source": [
        "# ,g_truth=True\n",
        "rn20_train_labels = new_labels(resnet_20, train_data, train_labels, t=temperature)\n",
        "rn20_test_labels = new_labels(resnet_20, test_data, test_labels, t=temperature)\n",
        "print(rn20_train_labels.shape)\n",
        "print(rn20_test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln7NRDkrfp6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "18c4ea1e-451e-420c-84cb-8e1dadc01615"
      },
      "source": [
        "rn14_train_labels = new_labels(resnet_14, train_data, train_labels, t=temperature)\n",
        "rn14_test_labels = new_labels(resnet_14, test_data, test_labels, t=temperature)\n",
        "print(rn14_train_labels.shape)\n",
        "print(rn14_test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNJnorjBfqN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "53bea16d-6ad9-4d4d-f086-5cdf861ef760"
      },
      "source": [
        "rn32_train_labels = new_labels(resnet_32, train_data, train_labels, t=temperature)\n",
        "rn32_test_labels = new_labels(resnet_32, test_data, test_labels, t=temperature)\n",
        "print(rn32_train_labels.shape)\n",
        "print(rn32_test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAUb7TP1einW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fb0c009-5a16-4d59-9a8c-c4186c840cf4"
      },
      "source": [
        "rn44_train_labels = new_labels(resnet_44, train_data, train_labels, t=temperature)\n",
        "rn44_test_labels = new_labels(resnet_44, test_data, test_labels, t=temperature)\n",
        "print(rn44_train_labels.shape)\n",
        "print(rn44_test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOikN8pD9XzH",
        "colab_type": "text"
      },
      "source": [
        "## Student Data Augmentation (with tf.data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhhnanMK9dIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "student_train_ds = tf.data.Dataset.from_tensor_slices((train_data, {'soft_prob_1':rn14_train_labels,'soft_prob_2':rn20_train_labels,'soft_prob_3':rn32_train_labels,'soft_prob_4':rn44_train_labels}))\n",
        "student_train_ds = student_train_ds.shuffle(10000, seed=seed)\n",
        "student_train_ds = student_train_ds.map(augment)\n",
        "student_train_ds = student_train_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "train_steps_per_epoch = tf.data.experimental.cardinality(student_train_ds)\n",
        "\n",
        "student_test_ds = tf.data.Dataset.from_tensor_slices((test_data, {'soft_prob_1':test_labels,'soft_prob_2':test_labels,'soft_prob_3':test_labels,'soft_prob_4':test_labels}))\n",
        "student_test_ds = student_test_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7E7amg6pE8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hinton datsets\n",
        "\n",
        "hinton_train_labels = [rn14_train_labels, rn20_train_labels, rn32_train_labels, rn44_train_labels]\n",
        "hinton_train_labels = np.array(hinton_train_labels)\n",
        "hinton_train_labels = hinton_train_labels.mean(axis=0)\n",
        "print(hinton_train_labels.shape)\n",
        "\n",
        "hinton_train_ds = tf.data.Dataset.from_tensor_slices((train_data, hinton_train_labels))\n",
        "hinton_train_ds = hinton_train_ds.shuffle(10000, seed=seed)\n",
        "hinton_train_ds = hinton_train_ds.map(augment)\n",
        "hinton_train_ds = hinton_train_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "hinton_test_labels = [rn14_test_labels, rn20_test_labels, rn32_test_labels, rn44_test_labels]\n",
        "hinton_test_labels = np.array(hinton_test_labels)\n",
        "hinton_test_labels = hinton_test_labels.mean(axis=0)\n",
        "\n",
        "hinton_test_ds = tf.data.Dataset.from_tensor_slices((test_data, hinton_test_labels))\n",
        "hinton_test_ds = hinton_test_ds.shuffle(10000, seed=seed)\n",
        "hinton_test_ds = hinton_test_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbzHUBThhzX7",
        "colab_type": "text"
      },
      "source": [
        "## Defining Hydra and Hinton Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY-nboLrsQyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "depth = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx9ZMVtnmc9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afaa5318-6ad6-47ef-8c68-1e773058f5a6"
      },
      "source": [
        "hydra = resnet_student_wo_GT((32,32,3), temperature=temperature, body_depth=depth, num_blocks_head=1, num_classes=10)\n",
        "hydra.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 16)   2320        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 16)   0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 32, 32, 16)   0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 16)   2320        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 16)   2320        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 32, 32, 16)   0           activation_18[0][0]              \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 32)   4640        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 32)   9248        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 32)   544         activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 32)   0           conv2d_24[0][0]                  \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 32)   9248        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 32)   9248        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 16, 16, 32)   0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 32)   9248        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 32)   9248        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 16, 16, 32)   0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 64)     18496       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 64)     36928       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 64)     2112        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 64)     0           conv2d_31[0][0]                  \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 64)     36928       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 64)     36928       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 64)     0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 64)     256         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 64)     256         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 64)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 64)     0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 64)     36928       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 64)     36928       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 64)     36928       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 64)     36928       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 64)     256         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 64)     0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 64)     0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 64)     0           activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 64)     0           activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 1, 1, 64)     0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 64)           0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 64)           0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "logits_1 (Dense)                (None, 10)           650         flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_2 (Dense)                (None, 10)           650         flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_3 (Dense)                (None, 10)           650         flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_4 (Dense)                (None, 10)           650         flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 10)           0           logits_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 10)           0           logits_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 10)           0           logits_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 10)           0           logits_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_1 (Activation)        (None, 10)           0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_2 (Activation)        (None, 10)           0           lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_3 (Activation)        (None, 10)           0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_4 (Activation)        (None, 10)           0           lambda_3[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 499,496\n",
            "Trainable params: 497,352\n",
            "Non-trainable params: 2,144\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvTCfiS5Us3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da1027e6-1743-4e23-e503-f0a56f2452fd"
      },
      "source": [
        "hinton_head = resnet_student((32,32,3), temperature=temperature, body_depth=depth, num_head=1, num_blocks_head=1, num_classes=10)\n",
        "hinton_head.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 32, 32, 16)   448         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 32, 32, 16)   64          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 32, 32, 16)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 16)   2320        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 32, 32, 16)   64          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 32, 32, 16)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 32, 32, 16)   2320        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 32, 32, 16)   64          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 32, 32, 16)   0           activation_39[0][0]              \n",
            "                                                                 batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 32, 32, 16)   0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 32, 32, 16)   2320        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 32, 32, 16)   64          conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 32, 32, 16)   0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 32, 32, 16)   2320        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 32, 32, 16)   64          conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 32, 32, 16)   0           activation_41[0][0]              \n",
            "                                                                 batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 32, 32, 16)   0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 32, 32, 16)   2320        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 32, 32, 16)   64          conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 32, 32, 16)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 32, 32, 16)   2320        activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 32, 32, 16)   64          conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 32, 32, 16)   0           activation_43[0][0]              \n",
            "                                                                 batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 32, 32, 16)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 32)   4640        activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 32)   128         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 16, 16, 32)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 32)   9248        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 32)   544         activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 32)   128         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 16, 16, 32)   0           conv2d_51[0][0]                  \n",
            "                                                                 batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 16, 16, 32)   0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 32)   9248        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 32)   128         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 16, 16, 32)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 32)   9248        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 32)   128         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 16, 16, 32)   0           activation_47[0][0]              \n",
            "                                                                 batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 16, 16, 32)   0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 32)   9248        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 32)   128         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 32)   9248        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 16, 16, 32)   128         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 16, 16, 32)   0           activation_49[0][0]              \n",
            "                                                                 batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 16, 16, 32)   0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 8, 8, 64)     18496       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 8, 8, 64)     36928       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 8, 8, 64)     2112        activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 8, 8, 64)     0           conv2d_58[0][0]                  \n",
            "                                                                 batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 8, 8, 64)     0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 8, 8, 64)     36928       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 8, 8, 64)     36928       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              \n",
            "                                                                 batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 8, 8, 64)     36928       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 8, 8, 64)     0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 8, 8, 64)     36928       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 8, 8, 64)     256         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 8, 8, 64)     0           activation_55[0][0]              \n",
            "                                                                 batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 1, 1, 64)     0           activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 64)           0           average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "logits_1 (Dense)                (None, 10)           650         flatten_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 10)           0           logits_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "softmax_1 (Activation)          (None, 10)           0           logits_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_1 (Activation)        (None, 10)           0           lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20)           0           softmax_1[0][0]                  \n",
            "                                                                 soft_prob_1[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTYKvSDzYkPg",
        "colab_type": "text"
      },
      "source": [
        "## Hinton Head Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1lslsYQh7s2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = ('models/hinton_cp/cp.ckpt')\n",
        "\n",
        "hinton_cp = keras.callbacks.ModelCheckpoint(filepath, verbose=1, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp2Pr9zew95e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "class TimingCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, logs={}):\n",
        "        self.logs=[]\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.starttime = timer()\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(timer()-self.starttime)\n",
        "\n",
        "time_hinton = TimingCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o5XL3bDcT1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "  lr = 1e-3\n",
        "  if epoch>=25:\n",
        "    lr*= 1e-1\n",
        "  elif epoch>=50:\n",
        "    lr*= 1e-2\n",
        "  elif epoch>=100:\n",
        "    lr*= 1e-3\n",
        "  return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DoZk4yfcIoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = tf.keras.optimizers.SGD(learning_rate=lr_schedule(0), momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arb81MZQiF6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hinton_head.compile(optimizer=sgd, loss=kd_loss, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "970mnE3diYsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8effbc74-691d-4d80-cc76-e5f19505636f"
      },
      "source": [
        "hinton_hist = hinton_head.fit(hinton_train_ds, epochs=150, validation_data=(hinton_test_ds), callbacks=[hinton_cp, time_hinton, lr_scheduler])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.6661 - accuracy: 0.2646\n",
            "Epoch 00001: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.6661 - accuracy: 0.2646 - val_loss: 0.6449 - val_accuracy: 0.3352 - lr: 0.0010\n",
            "Epoch 2/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5967 - accuracy: 0.3633\n",
            "Epoch 00002: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5967 - accuracy: 0.3634 - val_loss: 0.6010 - val_accuracy: 0.4024 - lr: 0.0010\n",
            "Epoch 3/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.4088\n",
            "Epoch 00003: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5674 - accuracy: 0.4088 - val_loss: 0.5769 - val_accuracy: 0.4370 - lr: 0.0010\n",
            "Epoch 4/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5474 - accuracy: 0.4332\n",
            "Epoch 00004: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5474 - accuracy: 0.4333 - val_loss: 0.5585 - val_accuracy: 0.4583 - lr: 0.0010\n",
            "Epoch 5/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5330 - accuracy: 0.4578\n",
            "Epoch 00005: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5330 - accuracy: 0.4579 - val_loss: 0.5495 - val_accuracy: 0.4716 - lr: 0.0010\n",
            "Epoch 6/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.5213 - accuracy: 0.4735\n",
            "Epoch 00006: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5213 - accuracy: 0.4735 - val_loss: 0.5351 - val_accuracy: 0.4911 - lr: 0.0010\n",
            "Epoch 7/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5122 - accuracy: 0.4850\n",
            "Epoch 00007: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5122 - accuracy: 0.4851 - val_loss: 0.5273 - val_accuracy: 0.5041 - lr: 0.0010\n",
            "Epoch 8/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.4991\n",
            "Epoch 00008: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.5022 - accuracy: 0.4992 - val_loss: 0.5328 - val_accuracy: 0.5017 - lr: 0.0010\n",
            "Epoch 9/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.5143\n",
            "Epoch 00009: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4923 - accuracy: 0.5143 - val_loss: 0.5128 - val_accuracy: 0.5281 - lr: 0.0010\n",
            "Epoch 10/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4838 - accuracy: 0.5259\n",
            "Epoch 00010: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4838 - accuracy: 0.5258 - val_loss: 0.5122 - val_accuracy: 0.5335 - lr: 0.0010\n",
            "Epoch 11/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.4750 - accuracy: 0.5413\n",
            "Epoch 00011: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4750 - accuracy: 0.5413 - val_loss: 0.4894 - val_accuracy: 0.5629 - lr: 0.0010\n",
            "Epoch 12/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.5490\n",
            "Epoch 00012: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4659 - accuracy: 0.5489 - val_loss: 0.4858 - val_accuracy: 0.5721 - lr: 0.0010\n",
            "Epoch 13/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.5630\n",
            "Epoch 00013: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4589 - accuracy: 0.5630 - val_loss: 0.4845 - val_accuracy: 0.5675 - lr: 0.0010\n",
            "Epoch 14/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.5737\n",
            "Epoch 00014: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4516 - accuracy: 0.5737 - val_loss: 0.4715 - val_accuracy: 0.5868 - lr: 0.0010\n",
            "Epoch 15/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.4454 - accuracy: 0.5812\n",
            "Epoch 00015: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4454 - accuracy: 0.5812 - val_loss: 0.4922 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 16/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4376 - accuracy: 0.5887\n",
            "Epoch 00016: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4377 - accuracy: 0.5887 - val_loss: 0.4668 - val_accuracy: 0.5919 - lr: 0.0010\n",
            "Epoch 17/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4317 - accuracy: 0.5981\n",
            "Epoch 00017: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4317 - accuracy: 0.5981 - val_loss: 0.4488 - val_accuracy: 0.6150 - lr: 0.0010\n",
            "Epoch 18/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.4251 - accuracy: 0.6053\n",
            "Epoch 00018: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4252 - accuracy: 0.6052 - val_loss: 0.4475 - val_accuracy: 0.6177 - lr: 0.0010\n",
            "Epoch 19/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4192 - accuracy: 0.6136\n",
            "Epoch 00019: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4192 - accuracy: 0.6136 - val_loss: 0.4397 - val_accuracy: 0.6254 - lr: 0.0010\n",
            "Epoch 20/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4149 - accuracy: 0.6198\n",
            "Epoch 00020: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4150 - accuracy: 0.6197 - val_loss: 0.4417 - val_accuracy: 0.6224 - lr: 0.0010\n",
            "Epoch 21/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.4094 - accuracy: 0.6273\n",
            "Epoch 00021: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4094 - accuracy: 0.6272 - val_loss: 0.4454 - val_accuracy: 0.6228 - lr: 0.0010\n",
            "Epoch 22/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.6328\n",
            "Epoch 00022: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.4038 - accuracy: 0.6328 - val_loss: 0.4327 - val_accuracy: 0.6321 - lr: 0.0010\n",
            "Epoch 23/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.6386\n",
            "Epoch 00023: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3998 - accuracy: 0.6386 - val_loss: 0.4375 - val_accuracy: 0.6325 - lr: 0.0010\n",
            "Epoch 24/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3951 - accuracy: 0.6406\n",
            "Epoch 00024: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3951 - accuracy: 0.6406 - val_loss: 0.4309 - val_accuracy: 0.6409 - lr: 0.0010\n",
            "Epoch 25/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3920 - accuracy: 0.6481\n",
            "Epoch 00025: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3920 - accuracy: 0.6481 - val_loss: 0.4274 - val_accuracy: 0.6383 - lr: 0.0010\n",
            "Epoch 26/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.6598\n",
            "Epoch 00026: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3831 - accuracy: 0.6598 - val_loss: 0.4129 - val_accuracy: 0.6609 - lr: 1.0000e-04\n",
            "Epoch 27/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3815 - accuracy: 0.6620\n",
            "Epoch 00027: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3816 - accuracy: 0.6618 - val_loss: 0.4101 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 28/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.6640\n",
            "Epoch 00028: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3805 - accuracy: 0.6640 - val_loss: 0.4108 - val_accuracy: 0.6632 - lr: 1.0000e-04\n",
            "Epoch 29/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3807 - accuracy: 0.6621\n",
            "Epoch 00029: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3808 - accuracy: 0.6620 - val_loss: 0.4105 - val_accuracy: 0.6633 - lr: 1.0000e-04\n",
            "Epoch 30/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.6625\n",
            "Epoch 00030: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3810 - accuracy: 0.6625 - val_loss: 0.4108 - val_accuracy: 0.6656 - lr: 1.0000e-04\n",
            "Epoch 31/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3803 - accuracy: 0.6636\n",
            "Epoch 00031: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3803 - accuracy: 0.6637 - val_loss: 0.4103 - val_accuracy: 0.6658 - lr: 1.0000e-04\n",
            "Epoch 32/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.6655\n",
            "Epoch 00032: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3795 - accuracy: 0.6655 - val_loss: 0.4098 - val_accuracy: 0.6638 - lr: 1.0000e-04\n",
            "Epoch 33/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.6658\n",
            "Epoch 00033: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3788 - accuracy: 0.6658 - val_loss: 0.4072 - val_accuracy: 0.6690 - lr: 1.0000e-04\n",
            "Epoch 34/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.6674\n",
            "Epoch 00034: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3782 - accuracy: 0.6674 - val_loss: 0.4074 - val_accuracy: 0.6675 - lr: 1.0000e-04\n",
            "Epoch 35/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3773 - accuracy: 0.6677\n",
            "Epoch 00035: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3773 - accuracy: 0.6677 - val_loss: 0.4068 - val_accuracy: 0.6694 - lr: 1.0000e-04\n",
            "Epoch 36/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.6656\n",
            "Epoch 00036: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3782 - accuracy: 0.6656 - val_loss: 0.4064 - val_accuracy: 0.6707 - lr: 1.0000e-04\n",
            "Epoch 37/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3765 - accuracy: 0.6680\n",
            "Epoch 00037: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3765 - accuracy: 0.6681 - val_loss: 0.4066 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
            "Epoch 38/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3769 - accuracy: 0.6668\n",
            "Epoch 00038: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3769 - accuracy: 0.6668 - val_loss: 0.4082 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 39/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3763 - accuracy: 0.6681\n",
            "Epoch 00039: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3763 - accuracy: 0.6681 - val_loss: 0.4075 - val_accuracy: 0.6699 - lr: 1.0000e-04\n",
            "Epoch 40/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3752 - accuracy: 0.6679\n",
            "Epoch 00040: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3752 - accuracy: 0.6679 - val_loss: 0.4047 - val_accuracy: 0.6716 - lr: 1.0000e-04\n",
            "Epoch 41/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3755 - accuracy: 0.6681\n",
            "Epoch 00041: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3756 - accuracy: 0.6680 - val_loss: 0.4045 - val_accuracy: 0.6733 - lr: 1.0000e-04\n",
            "Epoch 42/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3751 - accuracy: 0.6685\n",
            "Epoch 00042: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3751 - accuracy: 0.6685 - val_loss: 0.4049 - val_accuracy: 0.6713 - lr: 1.0000e-04\n",
            "Epoch 43/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.6711\n",
            "Epoch 00043: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3738 - accuracy: 0.6711 - val_loss: 0.4042 - val_accuracy: 0.6727 - lr: 1.0000e-04\n",
            "Epoch 44/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3742 - accuracy: 0.6697\n",
            "Epoch 00044: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3742 - accuracy: 0.6696 - val_loss: 0.4024 - val_accuracy: 0.6752 - lr: 1.0000e-04\n",
            "Epoch 45/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.6695\n",
            "Epoch 00045: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3736 - accuracy: 0.6695 - val_loss: 0.4051 - val_accuracy: 0.6715 - lr: 1.0000e-04\n",
            "Epoch 46/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3728 - accuracy: 0.6726\n",
            "Epoch 00046: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3728 - accuracy: 0.6726 - val_loss: 0.4020 - val_accuracy: 0.6761 - lr: 1.0000e-04\n",
            "Epoch 47/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.6699\n",
            "Epoch 00047: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3732 - accuracy: 0.6699 - val_loss: 0.4019 - val_accuracy: 0.6751 - lr: 1.0000e-04\n",
            "Epoch 48/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3721 - accuracy: 0.6735\n",
            "Epoch 00048: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3721 - accuracy: 0.6736 - val_loss: 0.4019 - val_accuracy: 0.6760 - lr: 1.0000e-04\n",
            "Epoch 49/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3724 - accuracy: 0.6695\n",
            "Epoch 00049: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3724 - accuracy: 0.6696 - val_loss: 0.4039 - val_accuracy: 0.6736 - lr: 1.0000e-04\n",
            "Epoch 50/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3714 - accuracy: 0.6733\n",
            "Epoch 00050: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3714 - accuracy: 0.6733 - val_loss: 0.3995 - val_accuracy: 0.6771 - lr: 1.0000e-04\n",
            "Epoch 51/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3709 - accuracy: 0.6740\n",
            "Epoch 00051: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3709 - accuracy: 0.6740 - val_loss: 0.4032 - val_accuracy: 0.6754 - lr: 1.0000e-04\n",
            "Epoch 52/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3703 - accuracy: 0.6759\n",
            "Epoch 00052: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3703 - accuracy: 0.6759 - val_loss: 0.3992 - val_accuracy: 0.6782 - lr: 1.0000e-04\n",
            "Epoch 53/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3696 - accuracy: 0.6733\n",
            "Epoch 00053: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3696 - accuracy: 0.6734 - val_loss: 0.3984 - val_accuracy: 0.6794 - lr: 1.0000e-04\n",
            "Epoch 54/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3696 - accuracy: 0.6754\n",
            "Epoch 00054: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3696 - accuracy: 0.6755 - val_loss: 0.3985 - val_accuracy: 0.6795 - lr: 1.0000e-04\n",
            "Epoch 55/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3686 - accuracy: 0.6766\n",
            "Epoch 00055: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3686 - accuracy: 0.6766 - val_loss: 0.3995 - val_accuracy: 0.6783 - lr: 1.0000e-04\n",
            "Epoch 56/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3683 - accuracy: 0.6771\n",
            "Epoch 00056: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3683 - accuracy: 0.6771 - val_loss: 0.3994 - val_accuracy: 0.6771 - lr: 1.0000e-04\n",
            "Epoch 57/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3681 - accuracy: 0.6758\n",
            "Epoch 00057: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3682 - accuracy: 0.6758 - val_loss: 0.3981 - val_accuracy: 0.6813 - lr: 1.0000e-04\n",
            "Epoch 58/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.6780\n",
            "Epoch 00058: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3685 - accuracy: 0.6780 - val_loss: 0.3963 - val_accuracy: 0.6831 - lr: 1.0000e-04\n",
            "Epoch 59/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3682 - accuracy: 0.6769\n",
            "Epoch 00059: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3682 - accuracy: 0.6769 - val_loss: 0.3993 - val_accuracy: 0.6792 - lr: 1.0000e-04\n",
            "Epoch 60/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3671 - accuracy: 0.6790\n",
            "Epoch 00060: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3671 - accuracy: 0.6790 - val_loss: 0.3976 - val_accuracy: 0.6829 - lr: 1.0000e-04\n",
            "Epoch 61/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.6789\n",
            "Epoch 00061: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3662 - accuracy: 0.6789 - val_loss: 0.3974 - val_accuracy: 0.6817 - lr: 1.0000e-04\n",
            "Epoch 62/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3667 - accuracy: 0.6803\n",
            "Epoch 00062: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 25ms/step - loss: 0.3666 - accuracy: 0.6803 - val_loss: 0.3999 - val_accuracy: 0.6777 - lr: 1.0000e-04\n",
            "Epoch 63/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.6835\n",
            "Epoch 00063: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3653 - accuracy: 0.6835 - val_loss: 0.3960 - val_accuracy: 0.6837 - lr: 1.0000e-04\n",
            "Epoch 64/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3656 - accuracy: 0.6811\n",
            "Epoch 00064: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3656 - accuracy: 0.6811 - val_loss: 0.3992 - val_accuracy: 0.6797 - lr: 1.0000e-04\n",
            "Epoch 65/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3649 - accuracy: 0.6810\n",
            "Epoch 00065: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3649 - accuracy: 0.6811 - val_loss: 0.3956 - val_accuracy: 0.6831 - lr: 1.0000e-04\n",
            "Epoch 66/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.6805\n",
            "Epoch 00066: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3653 - accuracy: 0.6806 - val_loss: 0.3959 - val_accuracy: 0.6841 - lr: 1.0000e-04\n",
            "Epoch 67/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.6805\n",
            "Epoch 00067: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3653 - accuracy: 0.6805 - val_loss: 0.3949 - val_accuracy: 0.6854 - lr: 1.0000e-04\n",
            "Epoch 68/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3639 - accuracy: 0.6824\n",
            "Epoch 00068: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3639 - accuracy: 0.6824 - val_loss: 0.3944 - val_accuracy: 0.6831 - lr: 1.0000e-04\n",
            "Epoch 69/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3641 - accuracy: 0.6804\n",
            "Epoch 00069: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 27ms/step - loss: 0.3641 - accuracy: 0.6804 - val_loss: 0.3940 - val_accuracy: 0.6876 - lr: 1.0000e-04\n",
            "Epoch 70/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3631 - accuracy: 0.6820\n",
            "Epoch 00070: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3632 - accuracy: 0.6820 - val_loss: 0.3959 - val_accuracy: 0.6860 - lr: 1.0000e-04\n",
            "Epoch 71/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3634 - accuracy: 0.6821\n",
            "Epoch 00071: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3634 - accuracy: 0.6821 - val_loss: 0.3931 - val_accuracy: 0.6858 - lr: 1.0000e-04\n",
            "Epoch 72/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3625 - accuracy: 0.6845\n",
            "Epoch 00072: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3625 - accuracy: 0.6845 - val_loss: 0.3936 - val_accuracy: 0.6888 - lr: 1.0000e-04\n",
            "Epoch 73/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.6842\n",
            "Epoch 00073: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3619 - accuracy: 0.6842 - val_loss: 0.3926 - val_accuracy: 0.6867 - lr: 1.0000e-04\n",
            "Epoch 74/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.6870\n",
            "Epoch 00074: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3610 - accuracy: 0.6870 - val_loss: 0.3932 - val_accuracy: 0.6862 - lr: 1.0000e-04\n",
            "Epoch 75/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3607 - accuracy: 0.6861\n",
            "Epoch 00075: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3606 - accuracy: 0.6862 - val_loss: 0.3905 - val_accuracy: 0.6909 - lr: 1.0000e-04\n",
            "Epoch 76/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3596 - accuracy: 0.6883\n",
            "Epoch 00076: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3596 - accuracy: 0.6884 - val_loss: 0.3917 - val_accuracy: 0.6874 - lr: 1.0000e-04\n",
            "Epoch 77/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3604 - accuracy: 0.6858\n",
            "Epoch 00077: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3604 - accuracy: 0.6858 - val_loss: 0.3915 - val_accuracy: 0.6909 - lr: 1.0000e-04\n",
            "Epoch 78/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3600 - accuracy: 0.6875\n",
            "Epoch 00078: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3600 - accuracy: 0.6875 - val_loss: 0.3920 - val_accuracy: 0.6851 - lr: 1.0000e-04\n",
            "Epoch 79/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3597 - accuracy: 0.6890\n",
            "Epoch 00079: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3597 - accuracy: 0.6889 - val_loss: 0.3933 - val_accuracy: 0.6865 - lr: 1.0000e-04\n",
            "Epoch 80/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3587 - accuracy: 0.6877\n",
            "Epoch 00080: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3587 - accuracy: 0.6876 - val_loss: 0.3897 - val_accuracy: 0.6906 - lr: 1.0000e-04\n",
            "Epoch 81/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3597 - accuracy: 0.6871\n",
            "Epoch 00081: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3596 - accuracy: 0.6872 - val_loss: 0.3912 - val_accuracy: 0.6873 - lr: 1.0000e-04\n",
            "Epoch 82/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3575 - accuracy: 0.6918\n",
            "Epoch 00082: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 41s 26ms/step - loss: 0.3576 - accuracy: 0.6918 - val_loss: 0.3894 - val_accuracy: 0.6888 - lr: 1.0000e-04\n",
            "Epoch 83/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3571 - accuracy: 0.6896\n",
            "Epoch 00083: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3571 - accuracy: 0.6896 - val_loss: 0.3881 - val_accuracy: 0.6933 - lr: 1.0000e-04\n",
            "Epoch 84/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.6891\n",
            "Epoch 00084: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 40s 26ms/step - loss: 0.3571 - accuracy: 0.6891 - val_loss: 0.3889 - val_accuracy: 0.6940 - lr: 1.0000e-04\n",
            "Epoch 85/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3565 - accuracy: 0.6913\n",
            "Epoch 00085: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3565 - accuracy: 0.6912 - val_loss: 0.3890 - val_accuracy: 0.6934 - lr: 1.0000e-04\n",
            "Epoch 86/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3556 - accuracy: 0.6913\n",
            "Epoch 00086: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3556 - accuracy: 0.6913 - val_loss: 0.3893 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
            "Epoch 87/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3571 - accuracy: 0.6893\n",
            "Epoch 00087: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3572 - accuracy: 0.6893 - val_loss: 0.3879 - val_accuracy: 0.6942 - lr: 1.0000e-04\n",
            "Epoch 88/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3561 - accuracy: 0.6917\n",
            "Epoch 00088: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3561 - accuracy: 0.6917 - val_loss: 0.3909 - val_accuracy: 0.6893 - lr: 1.0000e-04\n",
            "Epoch 89/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3550 - accuracy: 0.6917\n",
            "Epoch 00089: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3551 - accuracy: 0.6917 - val_loss: 0.3904 - val_accuracy: 0.6926 - lr: 1.0000e-04\n",
            "Epoch 90/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3556 - accuracy: 0.6909\n",
            "Epoch 00090: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3557 - accuracy: 0.6909 - val_loss: 0.3857 - val_accuracy: 0.6958 - lr: 1.0000e-04\n",
            "Epoch 91/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.6924\n",
            "Epoch 00091: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3550 - accuracy: 0.6924 - val_loss: 0.3868 - val_accuracy: 0.6932 - lr: 1.0000e-04\n",
            "Epoch 92/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.6909\n",
            "Epoch 00092: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3547 - accuracy: 0.6909 - val_loss: 0.3873 - val_accuracy: 0.6963 - lr: 1.0000e-04\n",
            "Epoch 93/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3543 - accuracy: 0.6927\n",
            "Epoch 00093: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3543 - accuracy: 0.6927 - val_loss: 0.3857 - val_accuracy: 0.6970 - lr: 1.0000e-04\n",
            "Epoch 94/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3537 - accuracy: 0.6943\n",
            "Epoch 00094: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3537 - accuracy: 0.6944 - val_loss: 0.3882 - val_accuracy: 0.6953 - lr: 1.0000e-04\n",
            "Epoch 95/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.6944\n",
            "Epoch 00095: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3529 - accuracy: 0.6944 - val_loss: 0.3876 - val_accuracy: 0.6937 - lr: 1.0000e-04\n",
            "Epoch 96/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3526 - accuracy: 0.6953\n",
            "Epoch 00096: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3526 - accuracy: 0.6954 - val_loss: 0.3862 - val_accuracy: 0.6957 - lr: 1.0000e-04\n",
            "Epoch 97/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.6949\n",
            "Epoch 00097: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3529 - accuracy: 0.6951 - val_loss: 0.3862 - val_accuracy: 0.6940 - lr: 1.0000e-04\n",
            "Epoch 98/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.6946\n",
            "Epoch 00098: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3526 - accuracy: 0.6946 - val_loss: 0.3838 - val_accuracy: 0.7004 - lr: 1.0000e-04\n",
            "Epoch 99/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3520 - accuracy: 0.6949\n",
            "Epoch 00099: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3520 - accuracy: 0.6948 - val_loss: 0.3844 - val_accuracy: 0.6956 - lr: 1.0000e-04\n",
            "Epoch 100/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3518 - accuracy: 0.6955\n",
            "Epoch 00100: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3518 - accuracy: 0.6955 - val_loss: 0.3831 - val_accuracy: 0.6986 - lr: 1.0000e-04\n",
            "Epoch 101/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.6963\n",
            "Epoch 00101: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3509 - accuracy: 0.6962 - val_loss: 0.3841 - val_accuracy: 0.6981 - lr: 1.0000e-04\n",
            "Epoch 102/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.6946\n",
            "Epoch 00102: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3513 - accuracy: 0.6947 - val_loss: 0.3840 - val_accuracy: 0.6980 - lr: 1.0000e-04\n",
            "Epoch 103/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3499 - accuracy: 0.6989\n",
            "Epoch 00103: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3498 - accuracy: 0.6989 - val_loss: 0.3798 - val_accuracy: 0.7025 - lr: 1.0000e-04\n",
            "Epoch 104/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.6987\n",
            "Epoch 00104: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3505 - accuracy: 0.6987 - val_loss: 0.3818 - val_accuracy: 0.7019 - lr: 1.0000e-04\n",
            "Epoch 105/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3495 - accuracy: 0.7003\n",
            "Epoch 00105: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3495 - accuracy: 0.7003 - val_loss: 0.3823 - val_accuracy: 0.7000 - lr: 1.0000e-04\n",
            "Epoch 106/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.7004\n",
            "Epoch 00106: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3480 - accuracy: 0.7004 - val_loss: 0.3818 - val_accuracy: 0.7017 - lr: 1.0000e-04\n",
            "Epoch 107/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3483 - accuracy: 0.6987\n",
            "Epoch 00107: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3483 - accuracy: 0.6987 - val_loss: 0.3826 - val_accuracy: 0.6999 - lr: 1.0000e-04\n",
            "Epoch 108/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3487 - accuracy: 0.7013\n",
            "Epoch 00108: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3487 - accuracy: 0.7013 - val_loss: 0.3790 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
            "Epoch 109/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3476 - accuracy: 0.7003\n",
            "Epoch 00109: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3477 - accuracy: 0.7002 - val_loss: 0.3791 - val_accuracy: 0.7045 - lr: 1.0000e-04\n",
            "Epoch 110/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3472 - accuracy: 0.7013\n",
            "Epoch 00110: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3471 - accuracy: 0.7014 - val_loss: 0.3794 - val_accuracy: 0.7033 - lr: 1.0000e-04\n",
            "Epoch 111/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.7016\n",
            "Epoch 00111: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3460 - accuracy: 0.7016 - val_loss: 0.3800 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
            "Epoch 112/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3465 - accuracy: 0.7016\n",
            "Epoch 00112: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3465 - accuracy: 0.7015 - val_loss: 0.3807 - val_accuracy: 0.7014 - lr: 1.0000e-04\n",
            "Epoch 113/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3460 - accuracy: 0.7037\n",
            "Epoch 00113: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3460 - accuracy: 0.7037 - val_loss: 0.3788 - val_accuracy: 0.7044 - lr: 1.0000e-04\n",
            "Epoch 114/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3449 - accuracy: 0.7044\n",
            "Epoch 00114: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3450 - accuracy: 0.7044 - val_loss: 0.3778 - val_accuracy: 0.7042 - lr: 1.0000e-04\n",
            "Epoch 115/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3454 - accuracy: 0.7025\n",
            "Epoch 00115: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3455 - accuracy: 0.7024 - val_loss: 0.3790 - val_accuracy: 0.7033 - lr: 1.0000e-04\n",
            "Epoch 116/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3461 - accuracy: 0.7001\n",
            "Epoch 00116: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3461 - accuracy: 0.7001 - val_loss: 0.3803 - val_accuracy: 0.7026 - lr: 1.0000e-04\n",
            "Epoch 117/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3454 - accuracy: 0.7021\n",
            "Epoch 00117: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3454 - accuracy: 0.7021 - val_loss: 0.3794 - val_accuracy: 0.7047 - lr: 1.0000e-04\n",
            "Epoch 118/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.7005\n",
            "Epoch 00118: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3455 - accuracy: 0.7005 - val_loss: 0.3769 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
            "Epoch 119/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.7065\n",
            "Epoch 00119: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3437 - accuracy: 0.7065 - val_loss: 0.3785 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 120/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3439 - accuracy: 0.7055\n",
            "Epoch 00120: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3439 - accuracy: 0.7055 - val_loss: 0.3784 - val_accuracy: 0.7049 - lr: 1.0000e-04\n",
            "Epoch 121/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.7068\n",
            "Epoch 00121: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3433 - accuracy: 0.7068 - val_loss: 0.3749 - val_accuracy: 0.7085 - lr: 1.0000e-04\n",
            "Epoch 122/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3427 - accuracy: 0.7062\n",
            "Epoch 00122: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3427 - accuracy: 0.7062 - val_loss: 0.3786 - val_accuracy: 0.7018 - lr: 1.0000e-04\n",
            "Epoch 123/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3421 - accuracy: 0.7088\n",
            "Epoch 00123: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3421 - accuracy: 0.7087 - val_loss: 0.3792 - val_accuracy: 0.7032 - lr: 1.0000e-04\n",
            "Epoch 124/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3427 - accuracy: 0.7087\n",
            "Epoch 00124: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3427 - accuracy: 0.7087 - val_loss: 0.3768 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 125/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3421 - accuracy: 0.7053\n",
            "Epoch 00125: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3421 - accuracy: 0.7054 - val_loss: 0.3747 - val_accuracy: 0.7079 - lr: 1.0000e-04\n",
            "Epoch 126/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.7072\n",
            "Epoch 00126: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3432 - accuracy: 0.7072 - val_loss: 0.3754 - val_accuracy: 0.7075 - lr: 1.0000e-04\n",
            "Epoch 127/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.7093\n",
            "Epoch 00127: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3424 - accuracy: 0.7093 - val_loss: 0.3732 - val_accuracy: 0.7080 - lr: 1.0000e-04\n",
            "Epoch 128/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.7100\n",
            "Epoch 00128: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3402 - accuracy: 0.7101 - val_loss: 0.3760 - val_accuracy: 0.7059 - lr: 1.0000e-04\n",
            "Epoch 129/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3403 - accuracy: 0.7084\n",
            "Epoch 00129: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3404 - accuracy: 0.7084 - val_loss: 0.3737 - val_accuracy: 0.7100 - lr: 1.0000e-04\n",
            "Epoch 130/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.7083\n",
            "Epoch 00130: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3407 - accuracy: 0.7084 - val_loss: 0.3742 - val_accuracy: 0.7082 - lr: 1.0000e-04\n",
            "Epoch 131/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3406 - accuracy: 0.7084\n",
            "Epoch 00131: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3406 - accuracy: 0.7084 - val_loss: 0.3766 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 132/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3393 - accuracy: 0.7082\n",
            "Epoch 00132: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3393 - accuracy: 0.7082 - val_loss: 0.3757 - val_accuracy: 0.7057 - lr: 1.0000e-04\n",
            "Epoch 133/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3390 - accuracy: 0.7111\n",
            "Epoch 00133: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3390 - accuracy: 0.7112 - val_loss: 0.3734 - val_accuracy: 0.7071 - lr: 1.0000e-04\n",
            "Epoch 134/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.7102\n",
            "Epoch 00134: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3389 - accuracy: 0.7102 - val_loss: 0.3711 - val_accuracy: 0.7093 - lr: 1.0000e-04\n",
            "Epoch 135/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3388 - accuracy: 0.7104\n",
            "Epoch 00135: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 37s 24ms/step - loss: 0.3388 - accuracy: 0.7104 - val_loss: 0.3720 - val_accuracy: 0.7085 - lr: 1.0000e-04\n",
            "Epoch 136/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3385 - accuracy: 0.7110\n",
            "Epoch 00136: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3385 - accuracy: 0.7110 - val_loss: 0.3731 - val_accuracy: 0.7079 - lr: 1.0000e-04\n",
            "Epoch 137/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3379 - accuracy: 0.7122\n",
            "Epoch 00137: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3379 - accuracy: 0.7122 - val_loss: 0.3757 - val_accuracy: 0.7074 - lr: 1.0000e-04\n",
            "Epoch 138/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3370 - accuracy: 0.7145\n",
            "Epoch 00138: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3370 - accuracy: 0.7145 - val_loss: 0.3725 - val_accuracy: 0.7123 - lr: 1.0000e-04\n",
            "Epoch 139/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3371 - accuracy: 0.7110\n",
            "Epoch 00139: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3371 - accuracy: 0.7110 - val_loss: 0.3712 - val_accuracy: 0.7108 - lr: 1.0000e-04\n",
            "Epoch 140/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3374 - accuracy: 0.7127\n",
            "Epoch 00140: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3374 - accuracy: 0.7127 - val_loss: 0.3702 - val_accuracy: 0.7107 - lr: 1.0000e-04\n",
            "Epoch 141/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3370 - accuracy: 0.7156\n",
            "Epoch 00141: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3370 - accuracy: 0.7155 - val_loss: 0.3690 - val_accuracy: 0.7147 - lr: 1.0000e-04\n",
            "Epoch 142/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3356 - accuracy: 0.7150\n",
            "Epoch 00142: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3356 - accuracy: 0.7151 - val_loss: 0.3696 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 143/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.7146\n",
            "Epoch 00143: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3364 - accuracy: 0.7146 - val_loss: 0.3688 - val_accuracy: 0.7159 - lr: 1.0000e-04\n",
            "Epoch 144/150\n",
            "1561/1563 [============================>.] - ETA: 0s - loss: 0.3358 - accuracy: 0.7134\n",
            "Epoch 00144: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3358 - accuracy: 0.7134 - val_loss: 0.3694 - val_accuracy: 0.7154 - lr: 1.0000e-04\n",
            "Epoch 145/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.7150\n",
            "Epoch 00145: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3342 - accuracy: 0.7150 - val_loss: 0.3698 - val_accuracy: 0.7121 - lr: 1.0000e-04\n",
            "Epoch 146/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3345 - accuracy: 0.7155\n",
            "Epoch 00146: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3345 - accuracy: 0.7155 - val_loss: 0.3698 - val_accuracy: 0.7147 - lr: 1.0000e-04\n",
            "Epoch 147/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.7152\n",
            "Epoch 00147: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.3344 - accuracy: 0.7152 - val_loss: 0.3685 - val_accuracy: 0.7135 - lr: 1.0000e-04\n",
            "Epoch 148/150\n",
            "1562/1563 [============================>.] - ETA: 0s - loss: 0.3337 - accuracy: 0.7150\n",
            "Epoch 00148: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3337 - accuracy: 0.7150 - val_loss: 0.3704 - val_accuracy: 0.7124 - lr: 1.0000e-04\n",
            "Epoch 149/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3340 - accuracy: 0.7160\n",
            "Epoch 00149: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.3340 - accuracy: 0.7160 - val_loss: 0.3690 - val_accuracy: 0.7134 - lr: 1.0000e-04\n",
            "Epoch 150/150\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.7165\n",
            "Epoch 00150: saving model to /content/drive/My Drive/MulTeacher Models/students/hinton_20_75_cp/cp.ckpt\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.3343 - accuracy: 0.7165 - val_loss: 0.3674 - val_accuracy: 0.7187 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDjSa6kyxM5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91a89f95-7fab-4d98-9bde-1975b12d25cf"
      },
      "source": [
        "print(np.sum(time_hinton.logs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5801.244107889999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtQ1t3pt0d73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df404152-af68-4ec0-d17a-2d30ee6d8a28"
      },
      "source": [
        "pred = hinton_head(test_data)\n",
        "(loss, acc) = kd_evaluate(test_labels, pred)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqU7bBcO0wtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9a87f2af-68c1-420a-a08c-422dca11bb0c"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(hinton_hist.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(hinton_hist.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EbTR6hk1KVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c137bb6a-ac83-4200-ead2-fa5bc250ab31"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(hinton_hist.history['loss'], label='Train Loss')\n",
        "plt.plot(hinton_hist.history['val_loss'], label='Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EGj8kLSuTX7",
        "colab_type": "text"
      },
      "source": [
        "## Hydra Weights Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLkV_aU1mS7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hinton_head_1 = tf.keras.models.Model(inputs= hinton_head.input, outputs= hinton_head.get_layer('soft_prob_1').output)\n",
        "\n",
        "\n",
        "body = 4+(3*int((depth-2)/6)-1-2)*7+(2*8)\n",
        "print(body)\n",
        "#head = body+11 #for training with ground truth\n",
        "#head = body+12 #for training without ground truth\n",
        "#head = body+19 #for training without ground truth 2 res-blocks per head\n",
        "\n",
        "for i in range(body):\n",
        "  hydra.layers[i].set_weights(hinton_head_1.layers[i].get_weights())\n",
        "  hydra.layers[i].trainable = False\n",
        "\n",
        "count = body\n",
        "for i in hinton_head_1.layers[body:]:\n",
        "  weights = i.get_weights()\n",
        "  for _ in range(4):\n",
        "    if count<len(hydra.layers):\n",
        "      hydra.layers[count].set_weights(weights)\n",
        "      count+=1\n",
        "\n",
        "\n",
        "for i in hydra.layers:\n",
        "  print(i, i.trainable)\n",
        "\n",
        "\n",
        "#hinton_softmax = hinton_head.layers[head].get_weights()\n",
        "#hinton_softprob = hinton_head.layers[head+1].get_weights()\n",
        "#hinton_concatenate = hinton_head.layers[head+2].get_weights()\n",
        "\n",
        "#hydra.layers[85].set_weights(hinton_softmax)\n",
        "#hydra.layers[86].set_weights(hinton_softprob)\n",
        "#hydra.layers[87].set_weights(hinton_softmax)\n",
        "#hydra.layers[88].set_weights(hinton_softprob)\n",
        "#hydra.layers[89].set_weights(hinton_softmax)\n",
        "#hydra.layers[90].set_weights(hinton_softprob)\n",
        "#hydra.layers[91].set_weights(hinton_softmax)\n",
        "#hydra.layers[92].set_weights(hinton_softprob)\n",
        "#hydra.layers[93].set_weights(hinton_concatenate)\n",
        "#hydra.layers[94].set_weights(hinton_concatenate)\n",
        "#hydra.layers[95].set_weights(hinton_concatenate)\n",
        "#hydra.layers[96].set_weights(hinton_concatenate)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZJA3-xKEAFKx",
        "colab": {}
      },
      "source": [
        "filepath = ('model/hydra_cp/cp.ckpt')\n",
        "\n",
        "hydra_cp = keras.callbacks.ModelCheckpoint(filepath, verbose=1, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vAOGQ6BCAFK1",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "  lr = 1e-3\n",
        "  if epoch>=50:\n",
        "    lr*= 1e-1\n",
        "  elif epoch>=100:\n",
        "    lr*= 1e-2\n",
        "  elif epoch>=150:\n",
        "    lr*= 1e-3\n",
        "  return lr\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afDER_DOJ4Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=4, verbose=0, mode='auto',\n",
        "    baseline=None, restore_best_weights=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kUl_0v38AFK3",
        "colab": {}
      },
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "class TimingCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, logs={}):\n",
        "        self.logs=[]\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.starttime = timer()\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(timer()-self.starttime)\n",
        "\n",
        "time_hydra = TimingCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJPR8NBANo3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = tf.keras.optimizers.SGD(learning_rate=lr_schedule(0), momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyrf3w0ixpPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbdfc17d-6eb6-468b-a0ac-428b34d69b8b"
      },
      "source": [
        "hydra.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 16)   2320        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 16)   0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 32, 32, 16)   0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 16)   2320        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 16)   2320        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 32, 32, 16)   0           activation_18[0][0]              \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 32)   4640        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 32)   9248        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 32)   544         activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 32)   0           conv2d_24[0][0]                  \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 32)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 32)   9248        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 32)   9248        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 16, 16, 32)   0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 32)   9248        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 32)   9248        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 16, 16, 32)   0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 64)     18496       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 64)     256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 64)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 64)     36928       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 64)     2112        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 64)     256         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 64)     0           conv2d_31[0][0]                  \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 64)     0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 64)     36928       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 64)     256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 64)     0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 64)     36928       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 64)     256         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 64)     0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 64)     0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 64)     256         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 64)     256         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 64)     256         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 64)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 64)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 64)     0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 64)     36928       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 64)     36928       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 64)     36928       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 64)     36928       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 64)     256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 64)     256         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 64)     0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 64)     0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 64)     0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 64)     0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 64)     0           activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 64)     0           activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 1, 1, 64)     0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 64)           0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 64)           0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "logits_1 (Dense)                (None, 10)           650         flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_2 (Dense)                (None, 10)           650         flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_3 (Dense)                (None, 10)           650         flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "logits_4 (Dense)                (None, 10)           650         flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 10)           0           logits_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 10)           0           logits_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 10)           0           logits_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 10)           0           logits_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_1 (Activation)        (None, 10)           0           lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_2 (Activation)        (None, 10)           0           lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_3 (Activation)        (None, 10)           0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "soft_prob_4 (Activation)        (None, 10)           0           lambda_3[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 499,496\n",
            "Trainable params: 299,048\n",
            "Non-trainable params: 200,448\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DlLGuHrBAFK4",
        "colab": {}
      },
      "source": [
        "kl_loss = tf.keras.losses.KLDivergence()\n",
        "ce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "cos_loss = tf.keras.losses.CosineSimilarity()\n",
        "\n",
        "hydra.compile(optimizer=sgd, loss= [ce_loss, ce_loss, ce_loss, ce_loss] , metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "daqGV9DoAFK6",
        "colab": {}
      },
      "source": [
        "hydra_hist = hydra.fit(student_train_ds, epochs=200, validation_data=(student_test_ds), callbacks=[hydra_cp, lr_scheduler])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}